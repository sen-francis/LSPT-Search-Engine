<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Ethics of artificial intelligence - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Ethics_of_artificial_intelligence","wgTitle":"Ethics of artificial intelligence","wgCurRevisionId":917618573,"wgRevisionId":917618573,"wgArticleId":13659583,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","CS1 maint: others","CS1 errors: dates","Webarchive template wayback links","All articles with unsourced statements","Articles with unsourced statements from May 2015","Articles with unsourced statements from November 2017","Articles to be expanded from May 2018","All articles to be expanded","Articles using small message boxes","Philosophy of artificial intelligence","Ethics of science and technology"],"wgBreakFrames":!1,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],
"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Ethics_of_artificial_intelligence","wgRelevantArticleId":13659583,"wgRequestId":"XaYxMgpAMEkAAFxHVBEAAABV","wgCSPNonce":!1,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia",
"wgWikibaseItemId":"Q12727779","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","jquery.makeCollapsible.styles":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.cite.tracking","ext.scribunto.logs","site","mediawiki.page.startup","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips",
"ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.1"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Ethics_of_artificial_intelligence"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Ethics_of_artificial_intelligence rootpage-Ethics_of_artificial_intelligence skin-vector action-view">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
</div>

	<h1 id="firstHeading" class="firstHeading" lang="en">Ethics of artificial intelligence</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#p-search">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%;width: 16em;"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Outline_of_artificial_intelligence" title="Outline of artificial intelligence">Artificial intelligence</a></th></tr><tr><th style="padding:0.1em">
<a href="/wiki/Artificial_intelligence#Goals" title="Artificial intelligence">Major goals</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Knowledge_representation_and_reasoning" title="Knowledge representation and reasoning">Knowledge reasoning</a></li>
<li><a href="/wiki/Automated_planning_and_scheduling" title="Automated planning and scheduling">Planning</a></li>
<li><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a></li>
<li><a href="/wiki/Natural_language_processing" title="Natural language processing">Natural language processing</a></li>
<li><a href="/wiki/Computer_vision" title="Computer vision">Computer vision</a></li>
<li><a href="/wiki/Robotics" title="Robotics">Robotics</a></li>
<li><a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">Artificial general intelligence</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Approaches</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Symbolic_artificial_intelligence" title="Symbolic artificial intelligence">Symbolic</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayesian networks</a></li>
<li><a href="/wiki/Evolutionary_algorithm" title="Evolutionary algorithm">Evolutionary algorithms</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
<a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a class="mw-selflink selflink">Ethics</a></li>
<li><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk</a></li>
<li><a href="/wiki/Turing_test" title="Turing test">Turing test</a></li>
<li><a href="/wiki/Chinese_room" title="Chinese room">Chinese room</a></li>
<li><a href="/wiki/AI_control_problem" title="AI control problem">Control problem</a></li>
<li><a href="/wiki/Friendly_artificial_intelligence" title="Friendly artificial intelligence">Friendly AI</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
<a href="/wiki/History_of_artificial_intelligence" title="History of artificial intelligence">History</a></th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Timeline_of_artificial_intelligence" title="Timeline of artificial intelligence">Timeline</a></li>
<li><a href="/wiki/Progress_in_artificial_intelligence" title="Progress in artificial intelligence">Progress</a></li>
<li><a href="/wiki/AI_winter" title="AI winter">AI winter</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Technology</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Applications_of_artificial_intelligence" title="Applications of artificial intelligence">Applications</a></li>
<li><a href="/wiki/List_of_artificial_intelligence_projects" title="List of artificial intelligence projects">Projects</a></li>
<li><a href="/wiki/List_of_programming_languages_for_artificial_intelligence" title="List of programming languages for artificial intelligence">Programming languages</a></li></ul></td>
</tr><tr><th style="padding:0.1em">
Glossary</th></tr><tr><td class="plainlist" style="padding:0 0.1em 0.4em">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary</a></li></ul></td>
</tr><tr><td style="text-align:right;font-size:115%"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Artificial_intelligence" title="Template:Artificial intelligence"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Artificial_intelligence" title="Template talk:Artificial intelligence"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Artificial_intelligence&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>The <b>ethics of artificial intelligence</b> is the part of the <a href="/wiki/Ethics_of_technology" title="Ethics of technology">ethics of technology</a> specific to <a href="/wiki/Robot" title="Robot">robots</a> and other <a href="/wiki/Artificial_intelligence" title="Artificial intelligence">artificially intelligent</a> beings. It is typically<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (May 2015)">citation needed</span></a></i>&#93;</sup> divided into <a href="/wiki/Roboethics" class="mw-redirect" title="Roboethics">roboethics</a>, a concern with the moral behavior of humans as they design, construct, use and treat artificially intelligent beings, and <a href="/wiki/Machine_ethics" title="Machine ethics">machine ethics</a>, which is concerned with the moral behavior of artificial moral agents (AMAs).
</p>
<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Robot_ethics"><span class="tocnumber">1</span> <span class="toctext">Robot ethics</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Robot_rights"><span class="tocnumber">1.1</span> <span class="toctext">Robot rights</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Threat_to_human_dignity"><span class="tocnumber">1.2</span> <span class="toctext">Threat to human dignity</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Transparency,_accountability,_and_open_source"><span class="tocnumber">1.3</span> <span class="toctext">Transparency, accountability, and open source</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-5"><a href="#Biases_in_AI_systems"><span class="tocnumber">2</span> <span class="toctext">Biases in AI systems</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Liability_for_Partial_or_Fully_Automated_Cars"><span class="tocnumber">3</span> <span class="toctext">Liability for Partial or Fully Automated Cars</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Weaponization_of_artificial_intelligence"><span class="tocnumber">4</span> <span class="toctext">Weaponization of artificial intelligence</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#Machine_ethics"><span class="tocnumber">5</span> <span class="toctext">Machine ethics</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Unintended_consequences"><span class="tocnumber">6</span> <span class="toctext">Unintended consequences</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#Organizations"><span class="tocnumber">7</span> <span class="toctext">Organizations</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#In_fiction"><span class="tocnumber">8</span> <span class="toctext">In fiction</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#Literature"><span class="tocnumber">9</span> <span class="toctext">Literature</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#See_also"><span class="tocnumber">10</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#Notes"><span class="tocnumber">11</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#External_links"><span class="tocnumber">12</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Robot_ethics">Robot ethics</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=1" title="Edit section: Robot ethics">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Robot_ethics" title="Robot ethics">Robot ethics</a></div>
<p>The term "robot ethics" (sometimes "roboethics") refers to the morality of how humans design, construct, use and treat robots and other artificially intelligent beings.<sup id="cite_ref-Veruggio2002_1-0" class="reference"><a href="#cite_note-Veruggio2002-1">&#91;1&#93;</a></sup> It considers both how artificially intelligent beings may be used to harm humans and how they may be used to benefit humans.
</p>
<h3><span class="mw-headline" id="Robot_rights">Robot rights</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=2" title="Edit section: Robot rights">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>"Robot rights" is the concept that people should have moral obligations towards their machines, similar to <a href="/wiki/Human_rights" title="Human rights">human rights</a> or <a href="/wiki/Animal_rights" title="Animal rights">animal rights</a>.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup> It has been suggested that robot rights, such as a right to exist and perform its own mission, could be linked to robot duty to serve human, by analogy with linking human rights to human duties before society.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> These could include the right to life and liberty, freedom of thought and expression and equality before the law.<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup>
The issue has been considered by the <a href="/wiki/Institute_for_the_Future" title="Institute for the Future">Institute for the Future</a><sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup>
and by the <a href="/wiki/United_Kingdom" title="United Kingdom">U.K.</a> <a href="/wiki/Department_of_Trade_and_Industry_(United_Kingdom)" title="Department of Trade and Industry (United Kingdom)">Department of Trade and Industry</a>.<sup id="cite_ref-TimesOnline_6-0" class="reference"><a href="#cite_note-TimesOnline-6">&#91;6&#93;</a></sup>
</p><p>Experts disagree whether specific and detailed laws will be required soon or safely in the distant future.<sup id="cite_ref-TimesOnline_6-1" class="reference"><a href="#cite_note-TimesOnline-6">&#91;6&#93;</a></sup> Glenn McGee reports that sufficiently humanoid robots may appear by 2020.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup> 
<a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a> sets the date at 2029.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup>
Another group of scientists meeting in 2007 supposed that at least 50 years had to pass before any sufficiently advanced system would exist.<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup>
</p><p>The rules for the 2003 <a href="/wiki/Loebner_Prize" title="Loebner Prize">Loebner Prize</a> competition envisioned the possibility of robots having rights of their own:
</p>
<blockquote><p>61. If, in any given year, a publicly available open source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible for the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right.<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup> </p></blockquote>
<p>In October 2017, the android <a href="/wiki/Sophia_(robot)" title="Sophia (robot)">Sophia</a> was granted "honorary" citizenship in <a href="/wiki/Saudi_Arabia" title="Saudi Arabia">Saudi Arabia</a>, though some observers found this to be more of a publicity stunt than a meaningful legal recognition.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup> Some saw this gesture as openly denigrating of <a href="/wiki/Human_rights" title="Human rights">human rights</a> and the <a href="/wiki/Rule_of_law" title="Rule of law">rule of law</a>.<sup id="cite_ref-bs_12-0" class="reference"><a href="#cite_note-bs-12">&#91;12&#93;</a></sup>
</p><p>The philosophy of <a href="/wiki/Sentientism" title="Sentientism">Sentientism</a> grants degrees of moral consideration to all sentient beings, primarily humans and most non-human animals. If artificial or alien intelligences show evidence of being <a href="/wiki/Sentience" title="Sentience">sentient</a>, this philosophy holds that they should be shown compassion and granted rights.
</p><p><a href="/wiki/Joanna_Bryson" title="Joanna Bryson">Joanna Bryson</a> has argued that creating AI that requires rights is both avoidable, and would in itself be unethical, both as a burden to the AI agents and to human society.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Threat_to_human_dignity">Threat to human dignity</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=3" title="Edit section: Threat to human dignity">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Computer_Power_and_Human_Reason" title="Computer Power and Human Reason">Computer Power and Human Reason</a></div>
<p><a href="/wiki/Joseph_Weizenbaum" title="Joseph Weizenbaum">Joseph Weizenbaum</a> argued in 1976 that AI technology should not be used to replace people in positions that require respect and care, such as any of these:
</p>
<ul><li>A customer service representative (AI technology is already used today for telephone-based <a href="/wiki/Interactive_voice_response" title="Interactive voice response">interactive voice response</a> systems)</li>
<li>A therapist (as was proposed by <a href="/wiki/Kenneth_Colby" title="Kenneth Colby">Kenneth Colby</a> in the 1970s)</li>
<li>A nursemaid for the elderly (as was reported by <a href="/wiki/Pamela_McCorduck" title="Pamela McCorduck">Pamela McCorduck</a> in her book <i>The Fifth Generation</i>)</li>
<li>A soldier</li>
<li>A judge</li>
<li>A police officer</li></ul>
<p>Weizenbaum explains that we require authentic feelings of <a href="/wiki/Empathy" title="Empathy">empathy</a> from people in these positions. If machines replace them, we will find ourselves alienated, devalued and frustrated. Artificial intelligence, if used in this way, represents a threat to human dignity. Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an "atrophy of the human spirit that comes from thinking of ourselves as computers."<sup id="cite_ref-MWZ_14-0" class="reference"><a href="#cite_note-MWZ-14">&#91;14&#93;</a></sup>
</p><p><a href="/wiki/Pamela_McCorduck" title="Pamela McCorduck">Pamela McCorduck</a> counters that, speaking for women and minorities "I'd rather take my chances with an impartial computer," pointing out that there are conditions where we would prefer to have automated  judges and police that have no personal agenda at all.<sup id="cite_ref-MWZ_14-1" class="reference"><a href="#cite_note-MWZ-14">&#91;14&#93;</a></sup> However, <a href="/wiki/Andreas_Kaplan" title="Andreas Kaplan">Kaplan</a> and Haenlein stress that AI systems are only as smart as the data used to train them since they are, in their essence, nothing more than fancy curve-fitting machines: Using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and engrained, which makes them even more difficult to spot and fight against.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup> AI founder <a href="/wiki/John_McCarthy_(computer_sc
ientist)" title="John McCarthy (computer scientist)">John McCarthy</a> objects to the moralizing tone of Weizenbaum's critique. "When moralizing is both vehement and vague, it invites authoritarian abuse," he writes.
</p><p><a href="/wiki/Bill_Hibbard" title="Bill Hibbard">Bill Hibbard</a><sup id="cite_ref-hibbard_2014_16-0" class="reference"><a href="#cite_note-hibbard_2014-16">&#91;16&#93;</a></sup> writes that "Human dignity requires that we strive to remove our ignorance of the nature of existence, and AI is necessary for that striving."
</p>
<h3><span id="Transparency.2C_accountability.2C_and_open_source"></span><span class="mw-headline" id="Transparency,_accountability,_and_open_source">Transparency, accountability, and open source</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=4" title="Edit section: Transparency, accountability, and open source">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/Bill_Hibbard" title="Bill Hibbard">Bill Hibbard</a> argues that because AI will have such a profound effect on humanity, AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts.<sup id="cite_ref-AGI-08a_17-0" class="reference"><a href="#cite_note-AGI-08a-17">&#91;17&#93;</a></sup> <a href="/wiki/Ben_Goertzel" title="Ben Goertzel">Ben Goertzel</a> and David Hart created <a href="/wiki/OpenCog" title="OpenCog">OpenCog</a> as an <a href="/wiki/Open-source_software" title="Open-source software">open source</a> framework for AI development.<sup id="cite_ref-AGI-08b_18-0" class="reference"><a href="#cite_note-AGI-08b-18">&#91;18&#93;</a></sup>  <a href="/wiki/OpenAI" title="OpenAI">OpenAI</a> is a non-profit AI research company created by <a href="/wiki/Elon_Musk" title="Elon Musk">Elon Musk</a>, <a href="/wiki/Sam_Altman" title="Sam Altman">Sam Altman</a> and others to develop open source AI beneficial to humanity.<sup id="cite_r
ef-OpenAI_19-0" class="reference"><a href="#cite_note-OpenAI-19">&#91;19&#93;</a></sup> There are numerous other open source AI developments.
</p><p>Unfortunately, making code open source does not make it comprehensible, which by many definitions means that the AI it codes is not transparent. The <a href="/wiki/IEEE" class="mw-redirect" title="IEEE">IEEE</a> has a <a href="/wiki/Technical_standards" class="mw-redirect" title="Technical standards">standardisation effort</a> on AI transparency.<sup id="cite_ref-p7001_20-0" class="reference"><a href="#cite_note-p7001-20">&#91;20&#93;</a></sup> The IEEE effort identifies multiple scales of transparency for different users. Further, there is concern that releasing the full capacity of contemporary AI to some organisations may be a public bad, that is, do more damage than good. For example, Microsoft has expressed concern about allowing universal access to its face recognition software, even for those who can pay for it. Microsoft posted an extraordinary blog on this topic, asking for government regulation to help determine the right thing to do.<sup id="cite_ref-WiredMS_21-0" class="reference"><a href="
#cite_note-WiredMS-21">&#91;21&#93;</a></sup>
</p><p>Not only companies, but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency, and through it, human accountability. <a rel="nofollow" class="external text" href="https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/">An updated collection (list) of AI Ethics is maintained by AlgorithmWatch.</a> This strategy has proven controversial, as some worry that it will slow the rate of innovation. Others argue that regulation leads to systemic stability more able to support innovation in the long term.<sup id="cite_ref-DeloitteGDPR_22-0" class="reference"><a href="#cite_note-DeloitteGDPR-22">&#91;22&#93;</a></sup> The <a href="/wiki/OECD" title="OECD">OECD</a>, <a href="/wiki/UN" class="mw-redirect" title="UN">UN</a>, <a href="/wiki/EU" class="mw-redirect" title="EU">EU</a>, and many countries are presently working on strategies for regulating AI, and finding appropriate legal frameworks.<sup id="cite_ref-23" class="reference"><a
 href="#cite_note-23">&#91;23&#93;</a></sup><sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup><sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> On June 26, the European Commission High-Level Expert Group on Artificial Intelligence (AI HLEG) published its “Policy and investment recommendations for trustworthy Artificial Intelligence”. This is the second deliverable of the AI HLEG and follows the April 2019 publication of the group’s Ethics Guidelines for Trustworthy AI. The new recommendations focus on four main areas: humans and society at large, the private sector, the public sector, and research and academia. The HLEG’s recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth, prosperity, and innovation, as well as the potential risks involved. The European Union has an ambition to lead the framing of policies governing AI globally. However, unless Europe accelerates deploym
ent and uptake and builds industrial, research, and development capabilities, its ability to do so will be limited.<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Biases_in_AI_systems">Biases in AI systems</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=5" title="Edit section: Biases in AI systems">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>AI has become increasingly inherent in facial and <a href="/wiki/Speech_recognition" title="Speech recognition">voice recognition</a> systems. Some of these systems have real business implications and directly impact people. These systems are vulnerable to biases and errors introduced by its human makers. Also, the data used to train these AI systems itself can have biases.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup><sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup><sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup><sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup> For instance, <a href="/wiki/Facial_recognition_system" title="Facial recognition system">facial recognition</a> algorithms made by Microsoft, IBM and Face++ all had biases when it came to detecting people’s gender.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></s
up> These AI systems were able to detect gender of white men more accurately than gender of darker skin men. Similarly, Amazon’s.com Inc’s  termination of AI hiring and recruitment is another example which exhibit AI cannot be fair. The algorithm preferred more male candidates than female. This was because Amazon’s system was trained with data collected over 10 year period that came mostly from male candidates.<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup>
</p><p>Bias can creep into algorithms in many ways. In a highly influential branch of AI known as "natural language processing," problems can arise from the "text corpus"—the source material the algorithm uses to learn about the relationships between different words.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup>
</p><p>Large companies such as IBM, Google, etc. started researching and addressing bias.<sup id="cite_ref-34" class="reference"><a href="#cite_note-34">&#91;34&#93;</a></sup><sup id="cite_ref-35" class="reference"><a href="#cite_note-35">&#91;35&#93;</a></sup><sup id="cite_ref-36" class="reference"><a href="#cite_note-36">&#91;36&#93;</a></sup>
</p><p>The problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law, and as more people without a deep technical understanding are tasked with deploying it. Some experts warn that algorithmic bias is already pervasive in many industries, and that almost no one is making an effort to identify or correct it.<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">&#91;37&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Liability_for_Partial_or_Fully_Automated_Cars">Liability for Partial or Fully Automated Cars</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=6" title="Edit section: Liability for Partial or Fully Automated Cars">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The wide use of partial to fully <a href="/wiki/Self-driving_car" title="Self-driving car">autonomous cars</a> seems to be imminent in the future. But fully autonomous technologies present new issues and challenges.<sup id="cite_ref-38" class="reference"><a href="#cite_note-38">&#91;38&#93;</a></sup><sup id="cite_ref-39" class="reference"><a href="#cite_note-39">&#91;39&#93;</a></sup><sup id="cite_ref-40" class="reference"><a href="#cite_note-40">&#91;40&#93;</a></sup> Recently, a debate over the legal liability have risen over the responsible party if these cars get into accidents.<sup id="cite_ref-41" class="reference"><a href="#cite_note-41">&#91;41&#93;</a></sup><sup id="cite_ref-42" class="reference"><a href="#cite_note-42">&#91;42&#93;</a></sup> In one of the reports <sup id="cite_ref-43" class="reference"><a href="#cite_note-43">&#91;43&#93;</a></sup> a driverless car hit a pedestrian and had a dilemma over whom to blame for the accident. Even though the driver was inside the car during the accident
, the controls were fully in the hand of computers. Before autonomous cars become widely used, these issues need to be tackled through new policies.<sup id="cite_ref-44" class="reference"><a href="#cite_note-44">&#91;44&#93;</a></sup><sup id="cite_ref-45" class="reference"><a href="#cite_note-45">&#91;45&#93;</a></sup><sup id="cite_ref-46" class="reference"><a href="#cite_note-46">&#91;46&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Weaponization_of_artificial_intelligence">Weaponization of artificial intelligence</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=7" title="Edit section: Weaponization of artificial intelligence">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Lethal_autonomous_weapon" title="Lethal autonomous weapon">Lethal autonomous weapon</a></div>
<p>Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.<sup id="cite_ref-Call_for_debate_on_killer_robots_47-0" class="reference"><a href="#cite_note-Call_for_debate_on_killer_robots-47">&#91;47&#93;</a></sup><sup id="cite_ref-48" class="reference"><a href="#cite_note-48">&#91;48&#93;</a></sup> The US Navy has funded a report which indicates that as <a href="/wiki/Military_robots" class="mw-redirect" title="Military robots">military robots</a> become more complex, there should be greater attention to implications of their ability to make autonomous decisions.<sup id="cite_ref-49" class="reference"><a href="#cite_note-49">&#91;49&#93;</a></sup><sup id="cite_ref-50" class="reference"><a href="#cite_note-50">&#91;50&#93;</a></sup> One researcher states that <a href="/wiki/Autonomous_robot" title="Autonomous robot">autonomous robots</a> might be more humane, as they could make decisions more effectively.<sup cl
ass="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (November 2017)">citation needed</span></a></i>&#93;</sup>
</p><p>Within this last decade, there has been intensive research in autonomous power with the ability to learn using assigned moral responsibilities. "The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots."<sup id="cite_ref-51" class="reference"><a href="#cite_note-51">&#91;51&#93;</a></sup> From a <a href="/wiki/Consequentialism" title="Consequentialism">consequentialist</a> view, there is a chance that robots will develop the ability to make their own logical decisions on who to kill and that is why there should be a set <a href="/wiki/Morality" title="Morality">moral</a> framework that the AI cannot override.<sup id="cite_ref-52" class="reference"><a href="#cite_note-52">&#91;52&#93;</a></sup>
</p><p>There has been a recent outcry with regard to the engineering of artificial-intelligence weapons that has included ideas of a robot takeover of mankind. AI weapons do present a type of danger different from that of human-controlled weapons. Many governments have begun to fund programs to develop AI weaponry. The United States Navy recently announced plans to develop <a href="/wiki/Unmanned_combat_aerial_vehicle" title="Unmanned combat aerial vehicle">autonomous drone weapons</a>, paralleling similar announcements by Russia and Korea respectively. Due to the potential of AI weapons becoming more dangerous than human-operated weapons, <a href="/wiki/Stephen_Hawking" title="Stephen Hawking">Stephen Hawking</a> and <a href="/wiki/Max_Tegmark" title="Max Tegmark">Max Tegmark</a> signed a "Future of Life" petition<sup id="cite_ref-53" class="reference"><a href="#cite_note-53">&#91;53&#93;</a></sup> to ban AI weapons. The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger an
d that action is required to avoid catastrophic disasters in the near future.<sup id="cite_ref-theatlantic.com_54-0" class="reference"><a href="#cite_note-theatlantic.com-54">&#91;54&#93;</a></sup>
</p><p>"If any major military power pushes ahead with the AI weapon development, a global <a href="/wiki/Arms_race" title="Arms race">arms race</a> is virtually inevitable, and the endpoint of this technological trajectory is obvious: autonomous weapons will become the Kalashnikovs of tomorrow", says the petition, which includes <a href="/wiki/Skype" title="Skype">Skype</a> co-founder <a href="/wiki/Jaan_Tallinn" title="Jaan Tallinn">Jaan Tallinn</a> and MIT professor of linguistics <a href="/wiki/Noam_Chomsky" title="Noam Chomsky">Noam Chomsky</a> as additional supporters against AI weaponry.<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">&#91;55&#93;</a></sup>
</p><p>Physicist and Astronomer Royal <a href="/wiki/Sir_Martin_Rees" class="mw-redirect" title="Sir Martin Rees">Sir Martin Rees</a> has warned of catastrophic instances like "dumb robots going rogue or a network that develops a mind of its own." <a href="/wiki/Huw_Price" title="Huw Price">Huw Price</a>, a colleague of Rees at Cambridge, has voiced a similar warning that humans might not survive when intelligence "escapes the constraints of biology." These two professors created the <a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a> at Cambridge University in the hope of avoiding this threat to human existence.<sup id="cite_ref-theatlantic.com_54-1" class="reference"><a href="#cite_note-theatlantic.com-54">&#91;54&#93;</a></sup>
</p><p>Regarding the potential for smarter-than-human systems to be employed militarily, the <a href="/wiki/Open_Philanthropy_Project" title="Open Philanthropy Project">Open Philanthropy Project</a> writes that these scenarios "seem potentially as important as the risks related to loss of control", but that research organizations investigating AI's long-run social impact have spent relatively little time on this concern: "this class of scenarios has not been a major focus for the organizations that have been most active in this space, such as the <a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a> (MIRI) and the <a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a> (FHI), and there seems to have been less analysis and debate regarding them".<sup id="cite_ref-givewell_56-0" class="reference"><a href="#cite_note-givewell-56">&#91;56&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Machine_ethics">Machine ethics</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=8" title="Edit section: Machine ethics">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Machine_ethics" title="Machine ethics">Machine ethics</a></div>
<p>Machine ethics (or machine morality) is the field of research concerned with designing <a href="/wiki/Moral_agency#Artificial_moral_agents" title="Moral agency">Artificial Moral Agents</a> (AMAs), robots or artificially intelligent computers that behave morally or as though moral.<sup id="cite_ref-Andersonweb_57-0" class="reference"><a href="#cite_note-Andersonweb-57">&#91;57&#93;</a></sup><sup id="cite_ref-Anderson2011_58-0" class="reference"><a href="#cite_note-Anderson2011-58">&#91;58&#93;</a></sup><sup id="cite_ref-Anderson2006_59-0" class="reference"><a href="#cite_note-Anderson2006-59">&#91;59&#93;</a></sup><sup id="cite_ref-Anderson2007_60-0" class="reference"><a href="#cite_note-Anderson2007-60">&#91;60&#93;</a></sup> To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, like the standard characterizations of <a href="/wiki/Agency_(philosophy)" title="Agency (philosophy)">agency</a>, <a href="/wiki/Rational_agent" title="Rational agent">rational a
gency</a>, <a href="/wiki/Moral_agency" title="Moral agency">moral agency</a>, and artificial agency, which are related to the concept of AMAs.<sup id="cite_ref-61" class="reference"><a href="#cite_note-61">&#91;61&#93;</a></sup>
</p><p><a href="/wiki/Isaac_Asimov" title="Isaac Asimov">Isaac Asimov</a> considered the issue in the 1950s in his <i><a href="/wiki/I,_Robot" title="I, Robot">I, Robot</a></i>.  At the insistence of his editor <a href="/wiki/John_W._Campbell_Jr." class="mw-redirect" title="John W. Campbell Jr.">John W. Campbell Jr.</a>, he proposed the <a href="/wiki/Three_Laws_of_Robotics" title="Three Laws of Robotics">Three Laws of Robotics</a> to govern artificially intelligent systems.  Much of his work was then spent testing the boundaries of his three laws to see where they would break down, or where they would create paradoxical or unanticipated behavior. His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances.<sup id="cite_ref-Asimov2008_62-0" class="reference"><a href="#cite_note-Asimov2008-62">&#91;62&#93;</a></sup> More recently, academics and many governments have challenged the idea that AI can itself be held accountable.<sup id="cite_ref-lacuna_63-0" class="reference"
><a href="#cite_note-lacuna-63">&#91;63&#93;</a></sup> A panel convened by the <a href="/wiki/United_Kingdom" title="United Kingdom">United Kingdom</a> in 2010 revised Asimov's laws to clarify that AI is the responsibility either of its manufacturers, or of its owner/operator.<sup id="cite_ref-principles_64-0" class="reference"><a href="#cite_note-principles-64">&#91;64&#93;</a></sup>
</p><p>In 2009, during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique Fédérale of <a href="/wiki/Lausanne" title="Lausanne">Lausanne</a> in <a href="/wiki/Switzerland" title="Switzerland">Switzerland</a>, robots that were programmed to cooperate with each other (in searching out a beneficial resource and avoiding a poisonous one) eventually learned to lie to each other in an attempt to hoard the beneficial resource.<sup id="cite_ref-65" class="reference"><a href="#cite_note-65">&#91;65&#93;</a></sup> One problem in this case may have been that the goals were "terminal" (i.e. in contrast, ultimate human motives typically have a quality of requiring never-ending learning).<sup id="cite_ref-SantosLang2002_66-0" class="reference"><a href="#cite_note-SantosLang2002-66">&#91;66&#93;</a></sup>
</p><p>Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.<sup id="cite_ref-Call_for_debate_on_killer_robots_47-1" class="reference"><a href="#cite_note-Call_for_debate_on_killer_robots-47">&#91;47&#93;</a></sup> The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.<sup id="cite_ref-67" class="reference"><a href="#cite_note-67">&#91;67&#93;</a></sup><sup id="cite_ref-68" class="reference"><a href="#cite_note-68">&#91;68&#93;</a></sup> The President of the <a href="/wiki/Association_for_the_Advancement_of_Artificial_Intelligence" title="Association for the Advancement of Artificial Intelligence">Association for the Advancement of Artificial Intelligence</a> has commissioned a study to look at this issue.<sup id="cite_ref-69" class="reference"><a href="#cite_note-69">&#91;69
&#93;</a></sup> They point to programs like the <a href="/wiki/Language_Acquisition_Device_(computer)" title="Language Acquisition Device (computer)">Language Acquisition Device</a> which can emulate human interaction.
</p><p><a href="/wiki/Vernor_Vinge" title="Vernor Vinge">Vernor Vinge</a> has suggested that a moment may come when some computers are smarter than humans. He calls this "<a href="/wiki/Technological_singularity" title="Technological singularity">the Singularity</a>."<sup id="cite_ref-nytimes_july09_70-0" class="reference"><a href="#cite_note-nytimes_july09-70">&#91;70&#93;</a></sup>  He suggests that it may be somewhat or possibly very dangerous for humans.<sup id="cite_ref-71" class="reference"><a href="#cite_note-71">&#91;71&#93;</a></sup> This is discussed by a philosophy called <a href="/wiki/Singularitarianism" title="Singularitarianism">Singularitarianism</a>. The <a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a> has suggested a need to build "<a href="/wiki/Friendly_AI" class="mw-redirect" title="Friendly AI">Friendly AI</a>", meaning that the advances which are already occurring with AI should also inclu
de an effort to make AI intrinsically friendly and humane.<sup id="cite_ref-72" class="reference"><a href="#cite_note-72">&#91;72&#93;</a></sup>
</p><p>In 2009, academics and technical experts attended a conference organized by the <a href="/wiki/Association_for_the_Advancement_of_Artificial_Intelligence" title="Association for the Advancement of Artificial Intelligence">Association for the Advancement of Artificial Intelligence</a> to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard. They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved "cockroach intelligence." They noted that self-awarene
ss as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls.<sup id="cite_ref-nytimes_july09_70-1" class="reference"><a href="#cite_note-nytimes_july09-70">&#91;70&#93;</a></sup>
</p><p>However, there is one technology in particular that could truly bring the possibility of robots with moral competence to reality. In a paper on the acquisition of moral values by robots, <a href="/wiki/Nayef_Al-Rodhan" title="Nayef Al-Rodhan">Nayef Al-Rodhan</a> mentions the case of <a href="/wiki/Neuromorphic_engineering" title="Neuromorphic engineering">neuromorphic</a> chips, which aim to process information similarly to humans, nonlinearly and with millions of interconnected artificial neurons.<sup id="cite_ref-73" class="reference"><a href="#cite_note-73">&#91;73&#93;</a></sup> Robots embedded with neuromorphic technology could learn and develop knowledge in a uniquely humanlike way. Inevitably, this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit - or if they end up developing human 'weaknesses' as well: selfishness, a pro-survival attitude, hesitation etc.
</p><p>In <i>Moral Machines: Teaching Robots Right from Wrong</i>,<sup id="cite_ref-Wallach2008_74-0" class="reference"><a href="#cite_note-Wallach2008-74">&#91;74&#93;</a></sup> Wendell Wallach and Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern <a href="/wiki/Normative_ethics" title="Normative ethics">normative theory</a> and by providing a platform for experimental investigation. As one example, it has introduced normative ethicists to the controversial issue of which specific <a href="/wiki/List_of_machine_learning_algorithms" class="mw-redirect" title="List of machine learning algorithms">learning algorithms</a> to use in machines. <a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a> and <a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a> have argued for <a href="/wiki/Decision_tree" title="Decision tree">decision trees</a> (such as <a href="/wik
i/ID3_algorithm" title="ID3 algorithm">ID3</a>) over <a href="/wiki/Artificial_neural_network" title="Artificial neural network">neural networks</a> and <a href="/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithms</a> on the grounds that decision trees obey modern social norms of transparency and predictability (e.g. <i><a href="/wiki/Stare_decisis" class="mw-redirect" title="Stare decisis">stare decisis</a></i>),<sup id="cite_ref-75" class="reference"><a href="#cite_note-75">&#91;75&#93;</a></sup> while Chris Santos-Lang argued in the opposite direction on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal "<a href="/wiki/Hacker_culture" title="Hacker culture">hackers</a>".<sup id="cite_ref-SantosLang2002_66-1" class="reference"><a href="#cite_note-SantosLang2002-66">&#91;66&#93;</a></sup>
</p><p>According to a 2019 report from the Center for the Governance of AI at the University of Oxford, 82% of Americans believe that robots and AI should be carefully managed. Concerns cited ranged from how AI is used in surveillance and in spreading fake content online (known as deepfakes when they include doctored video images and audio generated with help from AI) to cyberattacks, infringements on data privacy, hiring bias, autonomous vehicles, and drones that don’t require a human controller.<sup id="cite_ref-76" class="reference"><a href="#cite_note-76">&#91;76&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Unintended_consequences">Unintended consequences</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=9" title="Edit section: Unintended consequences">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Further information: <a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk from artificial general intelligence</a></div>
<p>Many researchers have argued that, by way of an "intelligence explosion" sometime in the 21st century, a self-improving AI could become so vastly more powerful than humans that we would not be able to stop it from achieving its goals.<sup id="cite_ref-Muehlhauser,_Luke_2012_77-0" class="reference"><a href="#cite_note-Muehlhauser,_Luke_2012-77">&#91;77&#93;</a></sup>
In his paper "Ethical Issues in Advanced Artificial Intelligence," philosopher <a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a> argues that artificial intelligence has the capability to bring about human extinction. He claims that general super-intelligence would be capable of independent initiative and of making its own plans, and may therefore be more appropriately thought of as an autonomous agent. Since artificial intellects need not share our human motivational tendencies, it would be up to the designers of the <a href="/wiki/Superintelligence" title="Superintelligence">super-intelligence</a> to specify its original motivations. In theory, a super-intelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its top goal, many uncontrolled <a href="/wiki/Unintended_consequences" title="Unintended consequences">unintended consequences</a> could arise. It could kill off all other agents, persuade them to change their beh
avior, or block their attempts at interference.<sup id="cite_ref-Bostrom,_Nick_2003_78-0" class="reference"><a href="#cite_note-Bostrom,_Nick_2003-78">&#91;78&#93;</a></sup>
</p><p>However, instead of overwhelming the human race and leading to our destruction, Bostrom has also asserted that super-intelligence can help us solve many difficult problems such as disease, poverty, and environmental destruction, and could help us to “enhance” ourselves.<sup id="cite_ref-79" class="reference"><a href="#cite_note-79">&#91;79&#93;</a></sup>
</p><p>The sheer complexity of human value systems makes it very difficult to make AI's motivations human-friendly.<sup id="cite_ref-Muehlhauser,_Luke_2012_77-1" class="reference"><a href="#cite_note-Muehlhauser,_Luke_2012-77">&#91;77&#93;</a></sup><sup id="cite_ref-Bostrom,_Nick_2003_78-1" class="reference"><a href="#cite_note-Bostrom,_Nick_2003-78">&#91;78&#93;</a></sup> Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not "common sense". According to <a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a>, there is little reason to suppose that an artificially designed mind would have such an adaptation.<sup id="cite_ref-80" class="reference"><a href="#cite_note-80">&#91;80&#93;</a></sup>
</p><p><a href="/wiki/Bill_Hibbard" title="Bill Hibbard">Bill Hibbard</a><sup id="cite_ref-hibbard_2014_16-1" class="reference"><a href="#cite_note-hibbard_2014-16">&#91;16&#93;</a></sup> proposes an AI design that avoids several types of unintended AI behavior including self-delusion, unintended instrumental actions, and corruption of the reward generator.
</p>
<h2><span class="mw-headline" id="Organizations">Organizations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=10" title="Edit section: Organizations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="box-Expand_section plainlinks metadata ambox mbox-small-left ambox-content" role="presentation"><tbody><tr><td class="mbox-image"><a href="/wiki/File:Wiki_letter_w_cropped.svg" class="image"><img alt="[icon]" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png" decoding="async" width="20" height="14" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x" data-file-width="44" data-file-height="31" /></a></td><td class="mbox-text"><div class="mbox-text-span">This section <b>needs expansion</b>. <small>You can help by <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=">adding to it</a>.</small>  <small class="date-container"><i>(<span class="date">May 2018</span>)
</i></small></div></td></tr></tbody></table>
<p><a href="/wiki/Amazon.com,_Inc." class="mw-redirect" title="Amazon.com, Inc.">Amazon</a>, <a href="/wiki/Google" title="Google">Google</a>, <a href="/wiki/Facebook" title="Facebook">Facebook</a>, <a href="/wiki/IBM" title="IBM">IBM</a>, and <a href="/wiki/Microsoft" title="Microsoft">Microsoft</a> have established a non-profit partnership to formulate best practices on artificial intelligence technologies, advance the public's understanding, and to serve as a platform about artificial intelligence. They stated: "This partnership on AI will conduct research, organize discussions, provide thought leadership, consult with relevant third parties, respond to questions from the public and media, and create educational material that advance the understanding of AI technologies including machine perception, learning, and automated reasoning."<sup id="cite_ref-81" class="reference"><a href="#cite_note-81">&#91;81&#93;</a></sup> Apple joined other tech companies as a founding member of the Partnership on AI in Janua
ry 2017. The corporate members will make financial and research contributions to the group, while engaging with the scientific community to bring academics onto the board.<sup id="cite_ref-82" class="reference"><a href="#cite_note-82">&#91;82&#93;</a></sup>
</p><p><a href="/w/index.php?title=The_Public_Voice&amp;action=edit&amp;redlink=1" class="new" title="The Public Voice (page does not exist)">The Public Voice</a> has proposed (in late 2018) a set of <a rel="nofollow" class="external text" href="https://thepublicvoice.org/ai-universal-guidelines/memo/">Universal Guidelines for Artificial Intelligence</a>, which has received many notable endorsements.
</p><p>The <a href="/wiki/IEEE" class="mw-redirect" title="IEEE">IEEE</a> put together a <a rel="nofollow" class="external text" href="https://standards.ieee.org/industry-connections/ec/autonomous-systems.html">Global Initiative on Ethics of Autonomous and Intelligent Systems</a> which has been creating and revising guidelines with the help of public input, and accepts as members many professionals from within and without its organisation.
</p><p>Traditionally, <a href="/wiki/Government" title="Government">government</a> has been used by societies to ensure ethics are observed through legislation and policing. There are now many efforts by national governments, as well as transnational government and <a href="/wiki/NGO" class="mw-redirect" title="NGO">non-government organisations</a> to ensure AI is ethically applied.
</p>
<ul><li>The <a href="/wiki/European_Commission" title="European Commission">European Commission</a> has a <a rel="nofollow" class="external text" href="https://ec.europa.eu/digital-single-market/en/high-level-expert-group-artificial-intelligence">High-Level Expert Group on Artificial Intelligence</a>.</li>
<li>The <a href="/wiki/OECD" title="OECD">OECD</a> on <a rel="nofollow" class="external text" href="http://www.oecd.org/going-digital/ai/">Artificial Intelligence</a></li>
<li>In the <a href="/wiki/United_States" title="United States">United States</a> the <a href="/wiki/Obama" class="mw-redirect" title="Obama">Obama</a> administration put together a <a rel="nofollow" class="external text" href="https://hbr.org/2016/12/the-obama-administrations-roadmap-for-ai-policy">Roadmap for AI Policy</a> (link is to <a href="/wiki/Harvard_Business_Review" title="Harvard Business Review">Harvard Business Review</a>'s account of it. The Obama Administration released two prominent <a href="/w/index.php?title=Whitepapers&amp;action=edit&amp;redlink=1" class="new" title="Whitepapers (page does not exist)">whitepapers</a> on the future and impact of AI. The Trump administration has not been actively engaged in AI regulation to date (January 2019).</li>
<li>The <a href="/wiki/Computing_Community_Consortium" title="Computing Community Consortium">Computing Community Consortium (CCC)</a> weighed in with a 100-plus page draft report<sup id="cite_ref-83" class="reference"><a href="#cite_note-83">&#91;83&#93;</a></sup> – <i>A 20-Year Community Roadmap for Artificial Intelligence Research in the US</i><sup id="cite_ref-84" class="reference"><a href="#cite_note-84">&#91;84&#93;</a></sup></li></ul>
<h2><span class="mw-headline" id="In_fiction">In fiction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=11" title="Edit section: In fiction">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Artificial_intelligence_in_fiction" title="Artificial intelligence in fiction">Artificial intelligence in fiction</a></div>
<p>The movie <i><a href="/wiki/The_Thirteenth_Floor" title="The Thirteenth Floor">The Thirteenth Floor</a></i> suggests a future where <a href="/wiki/Simulated_reality" title="Simulated reality">simulated worlds</a> with sentient inhabitants are created by computer <a href="/wiki/Game_console" class="mw-redirect" title="Game console">game consoles</a> for the purpose of entertainment. The movie <i><a href="/wiki/The_Matrix" title="The Matrix">The Matrix</a></i> suggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmost <a href="/wiki/Speciesism" title="Speciesism">Speciesism</a>. The short story "<a href="/wiki/The_Planck_Dive" title="The Planck Dive">The Planck Dive</a>" suggest a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non-sentient. The same idea can be found in the <a href="/wiki/Emergency_Medical_Hologram" class="mw-redirect" 
title="Emergency Medical Hologram">Emergency Medical Hologram</a> of <i><a href="/wiki/USS_Voyager_(NCC-74656)" class="mw-redirect" title="USS Voyager (NCC-74656)">Starship Voyager</a></i>, which is an apparently sentient copy of a reduced subset of the consciousness of its creator, <a href="/wiki/Lewis_Zimmerman" class="mw-redirect" title="Lewis Zimmerman">Dr. Zimmerman</a>, who, for the best motives, has created the system to give medical assistance in case of emergencies. The movies <i><a href="/wiki/Bicentennial_Man" class="mw-redirect" title="Bicentennial Man">Bicentennial Man</a></i> and <i><a href="/wiki/A.I._Artificial_Intelligence" title="A.I. Artificial Intelligence">A.I.</a></i> deal with the possibility of sentient robots that could love. <i><a href="/wiki/I,_Robot_(film)" title="I, Robot (film)">I, Robot</a></i> explored some aspects of Asimov's three laws. All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers.<sup class="noprint Inline-Template 
Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (May 2015)">citation needed</span></a></i>&#93;</sup>
</p><p>The ethics of artificial intelligence is one of several core themes in BioWare's <a href="/wiki/Mass_Effect" title="Mass Effect">Mass Effect</a> series of games.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (May 2015)">citation needed</span></a></i>&#93;</sup> It explores the scenario of a civilization accidentally creating AI through a rapid increase in computational power through a global scale <a href="/wiki/Neural_network" title="Neural network">neural network</a>. This event caused an ethical schism between those who felt bestowing organic rights upon the newly sentient Geth was appropriate and those who continued to see them as disposable machinery and fought to destroy them. Beyond the initial conflict, the complexity of the relationship between the machines and their creators is another ongoing theme throughout the sto
ry.
</p><p>Over time, debates have tended to focus less and less on <i>possibility</i> and more on <i>desirability</i>,<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (May 2015)">citation needed</span></a></i>&#93;</sup> as emphasized in the <a href="/wiki/Hugo_de_Garis#The_Artilect_War" title="Hugo de Garis">"Cosmist" and "Terran" debates</a> initiated by <a href="/wiki/Hugo_de_Garis" title="Hugo de Garis">Hugo de Garis</a> and <a href="/wiki/Kevin_Warwick" title="Kevin Warwick">Kevin Warwick</a>. A Cosmist, according to Hugo de Garis, is actually seeking to build more intelligent successors to the human species.
</p>
<h2><span class="mw-headline" id="Literature">Literature</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=12" title="Edit section: Literature">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The standard bibliography on ethics of AI is on <a rel="nofollow" class="external text" href="http://philpapers.org/browse/ethics-of-artificial-intelligence/">PhilPapers</a>. A recent collection is V.C. Müller(ed.) (2016).<sup id="cite_ref-85" class="reference"><a href="#cite_note-85">&#91;85&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=13" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Algorithmic_bias" title="Algorithmic bias">Algorithmic bias</a></li>
<li><a href="/wiki/Artificial_consciousness" title="Artificial consciousness">Artificial consciousness</a></li>
<li><a href="/wiki/Artificial_general_intelligence" title="Artificial general intelligence">Artificial general intelligence</a> (AGI)</li>
<li><a href="/wiki/Computer_ethics" title="Computer ethics">Computer ethics</a></li>
<li><a href="/wiki/Effective_altruism#Long_term_future_and_global_catastrophic_risks" title="Effective altruism">Effective altruism, the long term future and global catastrophic risks</a></li>
<li><a href="/wiki/Existential_risk_from_artificial_general_intelligence" title="Existential risk from artificial general intelligence">Existential risk from artificial general intelligence</a></li>
<li><a href="/wiki/Laws_of_Robotics" class="mw-redirect" title="Laws of Robotics">Laws of Robotics</a></li>
<li><a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Philosophy of artificial intelligence</a></li>
<li><a href="/wiki/Robot_ethics" title="Robot ethics">Roboethics</a></li>
<li><a href="/wiki/Robotic_governance" title="Robotic governance">Robotic Governance</a></li>
<li><i><a href="/wiki/Superintelligence:_Paths,_Dangers,_Strategies" title="Superintelligence: Paths, Dangers, Strategies">Superintelligence: Paths, Dangers, Strategies</a></i></li></ul>
<dl><dt>Researchers</dt></dl>
<ul><li><a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Nick Bostrom</a></li>
<li><a href="/wiki/Joanna_Bryson" title="Joanna Bryson">Joanna Bryson</a></li>
<li><a href="/wiki/Luciano_Floridi" title="Luciano Floridi">Luciano Floridi</a></li>
<li><a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a></li>
<li><a href="/wiki/Vincent_C._M%C3%BCller" title="Vincent C. Müller">Vincent C. Müller</a></li>
<li><a href="/wiki/Peter_Norvig" title="Peter Norvig">Peter Norvig</a></li>
<li><a href="/wiki/Steve_Omohundro" title="Steve Omohundro">Steve Omohundro</a></li>
<li><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Stuart J. Russell</a></li>
<li><a href="/wiki/Anders_Sandberg" title="Anders Sandberg">Anders Sandberg</a></li>
<li><a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a></li></ul>
<dl><dt>Organisations</dt></dl>
<ul><li><a href="/wiki/Centre_for_the_Study_of_Existential_Risk" title="Centre for the Study of Existential Risk">Centre for the Study of Existential Risk</a></li>
<li><a href="/wiki/Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a></li>
<li><a href="/wiki/Future_of_Life_Institute" title="Future of Life Institute">Future of Life Institute</a></li>
<li><a href="/wiki/Machine_Intelligence_Research_Institute" title="Machine Intelligence Research Institute">Machine Intelligence Research Institute</a></li>
<li><a href="/wiki/Partnership_on_AI" title="Partnership on AI">Partnership on AI</a></li></ul>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=14" title="Edit section: Notes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-Veruggio2002-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-Veruggio2002_1-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Veruggio, Gianmarco (2007). "The Roboethics Roadmap". Scuola di Robotica: 2. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.466.2810">10.1.1.466.2810</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+Roboethics+Roadmap&amp;rft.pages=2&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.466.2810&amp;rft.au=Veruggio%2C+Gianmarco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;jour
nal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><style data-mw-deduplicate="TemplateStyles:r886058088">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#5
55}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a href="/wiki/Woody_Evans" title="Woody Evans">Evans, Woody</a> (2015). "Posthuman Rights: Dimensions of Transhuman Worlds". <i>Teknokultura</i>. <b>12</b> (2). <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.5209%2Frev_TK.2015.v12.n2.49072">10.5209/rev_TK.2015.v12.n2.49072</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Teknokultura&amp;rft.atitle=Posthuman+Rights%3A+Dimensions+of+Transhuman+Worlds&amp;rft.volume=12&amp;rft.issue=2&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.5209%2Frev_TK.2015.v12.n2.49072&amp;rft.aulast=Evans&amp;rft.aufirst=Woody&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inl
ine-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a href="/w/index.php?title=Yurii_Sheliazhenko&amp;action=edit&amp;redlink=1" class="new" title="Yurii Sheliazhenko (page does not exist)">Sheliazhenko, Yurii</a> (2017). <a rel="nofollow" class="external text" href="http://cyberleninka.ru/article/n/artificial-personal-autonomy-and-concept-of-robot-rights">"Artificial Personal Autonomy and Concept of Robot Rights"</a>. European journal of law and political sciences<span class="reference-accessdate">. Retrieved <span class="nowrap">10 May</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Artificial+Personal+Autonomy+and+Concept+of+Robot+Rights&amp;rft.date=2017&amp;rft.aulast=Sheliazhenko&amp;rft.aufirst=Yurii&amp;rft_id=http%3A%2F%2Fcyberleninka.ru%2Farticle%2Fn%2Fartificial-personal-autonomy-and-concept-of-r
obot-rights&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">
The American Heritage Dictionary of the English Language, Fourth Edition</span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">
<cite class="citation news"><a rel="nofollow" class="external text" href="http://news.bbc.co.uk/2/hi/technology/6200005.stm">"Robots could demand legal rights"</a>. BBC News. December 21, 2006<span class="reference-accessdate">. Retrieved <span class="nowrap">January 3,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Robots+could+demand+legal+rights&amp;rft.date=2006-12-21&amp;rft_id=http%3A%2F%2Fnews.bbc.co.uk%2F2%2Fhi%2Ftechnology%2F6200005.stm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-TimesOnline-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-TimesOnline_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-TimesOnline_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">
<cite class="citation news">Henderson, Mark (April 24, 2007). <a rel="nofollow" class="external text" href="http://www.timesonline.co.uk/tol/news/uk/science/article1695546.ece">"Human rights for robots? We're getting carried away"</a>. <i>The Times Online</i>. The Times of London<span class="reference-accessdate">. Retrieved <span class="nowrap">May 2,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Times+Online&amp;rft.atitle=Human+rights+for+robots%3F+We%27re+getting+carried+away&amp;rft.date=2007-04-24&amp;rft.aulast=Henderson&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.timesonline.co.uk%2Ftol%2Fnews%2Fuk%2Fscience%2Farticle1695546.ece&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">
<cite class="citation web">McGee, Glenn. <a rel="nofollow" class="external text" href="https://www.the-scientist.com/column/a-robot-code-of-ethics-46522">"A Robot Code of Ethics"</a>. The Scientist.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+Robot+Code+of+Ethics&amp;rft.pub=The+Scientist&amp;rft.aulast=McGee&amp;rft.aufirst=Glenn&amp;rft_id=https%3A%2F%2Fwww.the-scientist.com%2Fcolumn%2Fa-robot-code-of-ethics-46522&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text">
<cite id="CITEREFKurzweil2005" class="citation book"><a href="/wiki/Ray_Kurzweil" title="Ray Kurzweil">Kurzweil, Ray</a> (2005). <a href="/wiki/The_Singularity_is_Near" class="mw-redirect" title="The Singularity is Near"><i>The Singularity is Near</i></a>. Penguin Books. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-670-03384-3" title="Special:BookSources/978-0-670-03384-3"><bdi>978-0-670-03384-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Singularity+is+Near&amp;rft.pub=Penguin+Books&amp;rft.date=2005&amp;rft.isbn=978-0-670-03384-3&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080522163926/http://www.independent.co.uk/news/science/the-big-question-should-the-human-race-be-worried-by-the-rise-of-robots-446107.html">The Big Question: Should the human race be worried by the rise of robots?</a>, Independent Newspaper, </span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://loebner03.hamill.co.uk/docs/LPC%20Official%20Rules%20v2.0.pdf">Loebner Prize Contest Official Rules — Version 2.0</a> The competition was directed by <a href="/wiki/David_Hamill" title="David Hamill">David Hamill</a> and the rules were developed by members of the Robitron Yahoo group.</span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://techcrunch.com/2017/10/26/saudi-arabia-robot-citizen-sophia/">Saudi Arabia bestows citizenship on a robot named Sophia</a></span>
</li>
<li id="cite_note-bs-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-bs_12-0">^</a></b></span> <span class="reference-text"><cite id="bs" class="citation news">Vincent, James (30 October 2017). <a rel="nofollow" class="external text" href="https://www.theverge.com/2017/10/30/16552006/robot-rights-citizenship-saudi-arabia-sophia">"Pretending to give a robot citizenship helps no one"</a>. The Verge.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Pretending+to+give+a+robot+citizenship+helps+no+one&amp;rft.date=2017-10-30&amp;rft.aulast=Vincent&amp;rft.aufirst=James&amp;rft_id=https%3A%2F%2Fwww.theverge.com%2F2017%2F10%2F30%2F16552006%2Frobot-rights-citizenship-saudi-arabia-sophia&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation book"><i>Close engagements with artificial companions&#160;: key social, psychological, ethical and design issues</i>. Wilks, Yorick, 1939-. Amsterdam: John Benjamins Pub. Co. 2010. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-9027249944" title="Special:BookSources/978-9027249944"><bdi>978-9027249944</bdi></a>. <a href="/wiki/OCLC" title="OCLC">OCLC</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/oclc/642206106">642206106</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Close+engagements+with+artificial+companions+%3A+key+social%2C+psychological%2C+ethical+and+design+issues&amp;rft.place=Amsterdam&amp;rft.pub=John+Benjamins+Pub.+Co&amp;rft.date=2010&amp;rft_id
=info%3Aoclcnum%2F642206106&amp;rft.isbn=978-9027249944&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: others (<a href="/wiki/Category:CS1_maint:_others" title="Category:CS1 maint: others">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-MWZ-14"><span class="mw-cite-backlink">^ <a href="#cite_ref-MWZ_14-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-MWZ_14-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a href="/wiki/Joseph_Weizenbaum" title="Joseph Weizenbaum">Joseph Weizenbaum</a>, quoted in <a href="#CITEREFMcCorduck2004">McCorduck 2004</a>, pp.&#160;356, 374–376</span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.sciencedirect.com/science/article/pii/S0007681318301393">Kaplan Andreas; Michael Haenlein (2018) Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence, Business Horizons, 62(1)</a></span>
</li>
<li id="cite_note-hibbard_2014-16"><span class="mw-cite-backlink">^ <a href="#cite_ref-hibbard_2014_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-hibbard_2014_16-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Hibbard, Bill (2014): <a rel="nofollow" class="external text" href="https://arxiv.org/abs/1411.1373">"Ethical Artificial Intelligence"</a>.</span>
</li>
<li id="cite_note-AGI-08a-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-AGI-08a_17-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.ssec.wisc.edu/~billh/g/hibbard_agi_workshop.pdf">Open Source AI.</a> Bill Hibbard. 2008 proceedings of the First Conference on Artificial General Intelligence, eds. Pei Wang, Ben Goertzel and Stan Franklin.</span>
</li>
<li id="cite_note-AGI-08b-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-AGI-08b_18-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.621&amp;rep=rep1&amp;type=pdf">OpenCog: A Software Framework for Integrative Artificial General Intelligence.</a> David Hart and Ben Goertzel. 2008 proceedings of the First Conference on Artificial General Intelligence, eds. Pei Wang, Ben Goertzel and Stan Franklin.</span>
</li>
<li id="cite_note-OpenAI-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-OpenAI_19-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/">Inside OpenAI, Elon Musk’s Wild Plan to Set Artificial Intelligence Free</a> Cade Metz, Wired 27 April 2016.</span>
</li>
<li id="cite_note-p7001-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-p7001_20-0">^</a></b></span> <span class="reference-text"><cite id="p7001" class="citation web"><a rel="nofollow" class="external text" href="https://standards.ieee.org/project/7001.html">"P7001 - Transparency of Autonomous Systems"</a>. <i>P7001 - Transparency of Autonomous Systems</i>. IEEE<span class="reference-accessdate">. Retrieved <span class="nowrap">10 January</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=P7001+-+Transparency+of+Autonomous+Systems&amp;rft.atitle=P7001+-+Transparency+of+Autonomous+Systems&amp;rft_id=https%3A%2F%2Fstandards.ieee.org%2Fproject%2F7001.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/>.</span>
</li>
<li id="cite_note-WiredMS-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-WiredMS_21-0">^</a></b></span> <span class="reference-text"><cite id="WiredMS" class="citation news">Thurm, Scott (July 13, 2018). <a rel="nofollow" class="external text" href="https://www.wired.com/story/microsoft-calls-for-federal-regulation-of-facial-recognition/">"MICROSOFT CALLS FOR FEDERAL REGULATION OF FACIAL RECOGNITION"</a>. Wired.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=MICROSOFT+CALLS+FOR+FEDERAL+REGULATION+OF+FACIAL+RECOGNITION&amp;rft.date=2018-07-13&amp;rft.aulast=Thurm&amp;rft.aufirst=Scott&amp;rft_id=https%3A%2F%2Fwww.wired.com%2Fstory%2Fmicrosoft-calls-for-federal-regulation-of-facial-recognition%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-DeloitteGDPR-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-DeloitteGDPR_22-0">^</a></b></span> <span class="reference-text"><cite id="DeloitteGDPR" class="citation web">Bastin, Roland; Wantz, Georges (June 2017). <a rel="nofollow" class="external text" href="https://www2.deloitte.com/content/dam/Deloitte/lu/Documents/technology/lu-general-data-protection-regulation-cross-industry-innovation-062017.pdf">"The General Data Protection Regulation Cross-industry innovation"</a> <span class="cs1-format">(PDF)</span>. <i>Inside magazine</i>. Deloitte.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Inside+magazine&amp;rft.atitle=The+General+Data+Protection+Regulation+Cross-industry+innovation&amp;rft.date=2017-06&amp;rft.aulast=Bastin&amp;rft.aufirst=Roland&amp;rft.au=Wantz%2C+Georges&amp;rft_id=https%3A%2F%2Fwww2.deloitte.com%2Fcontent%2Fdam%2FDeloitte%2Flu%2FDocuments%2Ftechnology%2Flu-general-data-protec
tion-regulation-cross-industry-innovation-062017.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://news.un.org/en/story/2017/06/558962-un-artificial-intelligence-summit-aims-tackle-poverty-humanitys-grand">"UN artificial intelligence summit aims to tackle poverty, humanity's 'grand challenges<span class="cs1-kern-right">'</span>"</a>. <i>UN News</i>. 2017-06-07<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=UN+News&amp;rft.atitle=UN+artificial+intelligence+summit+aims+to+tackle+poverty%2C+humanity%27s+%27grand+challenges%27&amp;rft.date=2017-06-07&amp;rft_id=https%3A%2F%2Fnews.un.org%2Fen%2Fstory%2F2017%2F06%2F558962-un-artificial-intelligence-summit-aims-tackle-poverty-humanitys-grand&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEt
hics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.oecd.org/going-digital/ai/">"Artificial intelligence - Organisation for Economic Co-operation and Development"</a>. <i>www.oecd.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.oecd.org&amp;rft.atitle=Artificial+intelligence+-+Organisation+for+Economic+Co-operation+and+Development&amp;rft_id=http%3A%2F%2Fwww.oecd.org%2Fgoing-digital%2Fai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation web">Anonymous (2018-06-14). <a rel="nofollow" class="external text" href="https://ec.europa.eu/digital-single-market/en/european-ai-alliance">"The European AI Alliance"</a>. <i>Digital Single Market - European Commission</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Digital+Single+Market+-+European+Commission&amp;rft.atitle=The+European+AI+Alliance&amp;rft.date=2018-06-14&amp;rft.au=Anonymous&amp;rft_id=https%3A%2F%2Fec.europa.eu%2Fdigital-single-market%2Fen%2Feuropean-ai-alliance&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://cdt.org/blog/eu-tech-policy-brief-july-2019-recap/">"EU Tech Policy Brief: July 2019 Recap"</a>. <i>Center for Democracy &amp; Technology</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-08-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Center+for+Democracy+%26+Technology&amp;rft.atitle=EU+Tech+Policy+Brief%3A+July+2019+Recap&amp;rft_id=https%3A%2F%2Fcdt.org%2Fblog%2Feu-tech-policy-brief-july-2019-recap%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><cite class="citation web">Society, DeepMind Ethics &amp; (2018-03-14). <a rel="nofollow" class="external text" href="https://medium.com/@Ethics_Society/the-case-for-fairer-algorithms-c008a12126f8">"The case for fairer algorithms - DeepMind Ethics &amp; Society"</a>. <i>Medium</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Medium&amp;rft.atitle=The+case+for+fairer+algorithms+-+DeepMind+Ethics+%26+Society&amp;rft.date=2018-03-14&amp;rft.aulast=Society&amp;rft.aufirst=DeepMind+Ethics+%26&amp;rft_id=https%3A%2F%2Fmedium.com%2F%40Ethics_Society%2Fthe-case-for-fairer-algorithms-c008a12126f8&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated
-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://social.techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/">"5 unexpected sources of bias in artificial intelligence"</a>. <i>TechCrunch</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=TechCrunch&amp;rft.atitle=5+unexpected+sources+of+bias+in+artificial+intelligence&amp;rft_id=http%3A%2F%2Fsocial.techcrunch.com%2F2016%2F12%2F10%2F5-unexpected-sources-of-bias-in-artificial-intelligence%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><cite class="citation web">Knight, Will. <a rel="nofollow" class="external text" href="https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/">"Google's AI chief says forget Elon Musk's killer robots, and worry about bias in AI systems instead"</a>. <i>MIT Technology Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=Google%E2%80%99s+AI+chief+says+forget+Elon+Musk%E2%80%99s+killer+robots%2C+and+worry+about+bias+in+AI+systems+instead&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F608986%2Fforget-killer-robotsbias-is-the-real-ai-danger%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthic
s+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><cite class="citation web">Villasenor, John (2019-01-03). <a rel="nofollow" class="external text" href="https://www.brookings.edu/blog/techtank/2019/01/03/artificial-intelligence-and-bias-four-key-challenges/">"Artificial intelligence and bias: Four key challenges"</a>. <i>Brookings</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Brookings&amp;rft.atitle=Artificial+intelligence+and+bias%3A+Four+key+challenges&amp;rft.date=2019-01-03&amp;rft.aulast=Villasenor&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.brookings.edu%2Fblog%2Ftechtank%2F2019%2F01%2F03%2Fartificial-intelligence-and-bias-four-key-challenges%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><cite class="citation news">Lohr, Steve (2018-02-09). <a rel="nofollow" class="external text" href="https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html">"Facial Recognition Is Accurate, if You're a White Guy"</a>. <i>The New York Times</i>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0362-4331">0362-4331</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-05-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Facial+Recognition+Is+Accurate%2C+if+You%27re+a+White+Guy&amp;rft.date=2018-02-09&amp;rft.issn=0362-4331&amp;rft.aulast=Lohr&amp;rft.aufirst=Steve
&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2018%2F02%2F09%2Ftechnology%2Ffacial-recognition-race-artificial-intelligence.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><cite class="citation news"><a rel="nofollow" class="external text" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G">"Amazon scraps secret AI recruiting tool that showed bias against women"</a>. <i>Reuters</i>. 2018-10-10<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-05-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Reuters&amp;rft.atitle=Amazon+scraps+secret+AI+recruiting+tool+that+showed+bias+against+women&amp;rft.date=2018-10-10&amp;rft_id=https%3A%2F%2Fwww.reuters.com%2Farticle%2Fus-amazon-com-jobs-automation-insight-idUSKCN1MK08G&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span
>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://techxplore.com/news/2019-07-bias-ai.html">"Eliminating bias in AI"</a>. <i>techxplore.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=techxplore.com&amp;rft.atitle=Eliminating+bias+in+AI&amp;rft_id=https%3A%2F%2Ftechxplore.com%2Fnews%2F2019-07-bias-ai.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><cite class="citation web">Olson, Parmy. <a rel="nofollow" class="external text" href="https://www.forbes.com/sites/parmyolson/2018/03/13/google-deepmind-ai-machine-learning-bias/">"Google's DeepMind Has An Idea For Stopping Biased AI"</a>. <i>Forbes</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=Google%27s+DeepMind+Has+An+Idea+For+Stopping+Biased+AI&amp;rft.aulast=Olson&amp;rft.aufirst=Parmy&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fparmyolson%2F2018%2F03%2F13%2Fgoogle-deepmind-ai-machine-learning-bias%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058
088"/></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://developers.google.com/machine-learning/fairness-overview/">"Machine Learning Fairness | ML Fairness"</a>. <i>Google Developers</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Developers&amp;rft.atitle=Machine+Learning+Fairness+%7C+ML+Fairness&amp;rft_id=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Ffairness-overview%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.research.ibm.com/5-in-5/ai-and-bias/">"AI and bias - IBM Research - US"</a>. <i>www.research.ibm.com</i>. REPLACE<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.research.ibm.com&amp;rft.atitle=AI+and+bias+-+IBM+Research+-+US&amp;rft.chron=REPLACE&amp;rft_id=https%3A%2F%2Fwww.research.ibm.com%2F5-in-5%2Fai-and-bias%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span> <span class="cs1-visible-error error citation-comment">Check date values in: <code class="cs1-code">&#124;date=</code> (<a href="/wiki/Help:CS1_errors#bad_date" title="Help:CS1 errors">help</a>)</span><link rel="mw
-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><cite class="citation web">Knight, Will. <a rel="nofollow" class="external text" href="https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/">"Google's AI chief says forget Elon Musk's killer robots, and worry about bias in AI systems instead"</a>. <i>MIT Technology Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=Google%E2%80%99s+AI+chief+says+forget+Elon+Musk%E2%80%99s+killer+robots%2C+and+worry+about+bias+in+AI+systems+instead&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F608986%2Fforget-killer-robotsbias-is-the-real-ai-danger%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthic
s+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-38">^</a></b></span> <span class="reference-text"><cite class="citation news">Davies, Alex (2016-02-29). <a rel="nofollow" class="external text" href="https://www.wired.com/2016/02/googles-self-driving-car-may-caused-first-crash/">"Google's Self-Driving Car Caused Its First Crash"</a>. <i>Wired</i>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1059-1028">1059-1028</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=Google%27s+Self-Driving+Car+Caused+Its+First+Crash&amp;rft.date=2016-02-29&amp;rft.issn=1059-1028&amp;rft.aulast=Davies&amp;rft.aufirst=Alex&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2016%2F02%2Fgo
ogles-self-driving-car-may-caused-first-crash%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-39">^</a></b></span> <span class="reference-text"><cite class="citation"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=List_of_self-driving_car_fatalities&amp;oldid=900361661">"List of self-driving car fatalities"</a>, <i>Wikipedia</i>, 2019-06-05<span class="reference-accessdate">, retrieved <span class="nowrap">2019-07-26</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wikipedia&amp;rft.atitle=List+of+self-driving+car+fatalities&amp;rft.date=2019-06-05&amp;rft_id=https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DList_of_self-driving_car_fatalities%26oldid%3D900361661&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-40">^</a></b></span> <span class="reference-text"><cite class="citation news">Levin, Sam; Wong, Julia Carrie (2018-03-19). <a rel="nofollow" class="external text" href="https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe">"Self-driving Uber kills Arizona woman in first fatal crash involving pedestrian"</a>. <i>The Guardian</i>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0261-3077">0261-3077</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Guardian&amp;rft.atitle=Self-driving+Uber+kills+Arizona+woman+in+first+fatal+crash+involving+pedestrian&amp;rft.date=2018-03-19&amp;rft.i
ssn=0261-3077&amp;rft.aulast=Levin&amp;rft.aufirst=Sam&amp;rft.au=Wong%2C+Julia+Carrie&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2018%2Fmar%2F19%2Fuber-self-driving-car-kills-woman-arizona-tempe&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://futurism.com/who-responsible-when-self-driving-car-accident">"Who is responsible when a self-driving car has an accident?"</a>. <i>Futurism</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Futurism&amp;rft.atitle=Who+is+responsible+when+a+self-driving+car+has+an+accident%3F&amp;rft_id=https%3A%2F%2Ffuturism.com%2Fwho-responsible-when-self-driving-car-accident&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text"><cite class="citation web">Radio, Business; Policy, Law and Public; Podcasts; America, North. <a rel="nofollow" class="external text" href="https://knowledge.wharton.upenn.edu/article/automated-car-accidents/">"Autonomous Car Crashes: Who - or What - Is to Blame?"</a>. <i>Knowledge@Wharton</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Knowledge%40Wharton&amp;rft.atitle=Autonomous+Car+Crashes%3A+Who+-+or+What+-+Is+to+Blame%3F&amp;rft.aulast=Radio&amp;rft.aufirst=Business&amp;rft.au=Policy%2C+Law+and+Public&amp;rft.au=Podcasts&amp;rft.au=America%2C+North&amp;rft_id=https%3A%2F%2Fknowledge.wharton.upenn.edu%2Farticle%2Fautomated-car-accidents%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+in
telligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-43">^</a></b></span> <span class="reference-text"><cite class="citation web">Delbridge, Emily. <a rel="nofollow" class="external text" href="https://www.thebalance.com/driverless-car-accidents-4171792">"Driverless Cars Gone Wild"</a>. <i>The Balance</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-05-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Balance&amp;rft.atitle=Driverless+Cars+Gone+Wild&amp;rft.aulast=Delbridge&amp;rft.aufirst=Emily&amp;rft_id=https%3A%2F%2Fwww.thebalance.com%2Fdriverless-car-accidents-4171792&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.gov.uk/government/publications/driverless-cars-in-the-uk-a-regulatory-review">"Regulations for driverless cars"</a>. <i>GOV.UK</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GOV.UK&amp;rft.atitle=Regulations+for+driverless+cars&amp;rft_id=https%3A%2F%2Fwww.gov.uk%2Fgovernment%2Fpublications%2Fdriverless-cars-in-the-uk-a-regulatory-review&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://cyberlaw.stanford.edu/wiki/index.php/Automated_Driving:_Legislative_and_Regulatory_Action">"Automated Driving: Legislative and Regulatory Action - CyberWiki"</a>. <i>cyberlaw.stanford.edu</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=cyberlaw.stanford.edu&amp;rft.atitle=Automated+Driving%3A+Legislative+and+Regulatory+Action+-+CyberWiki&amp;rft_id=https%3A%2F%2Fcyberlaw.stanford.edu%2Fwiki%2Findex.php%2FAutomated_Driving%3A_Legislative_and_Regulatory_Action&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r88605
8088"/></span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.ncsl.org/research/transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx">"Autonomous Vehicles | Self-Driving Vehicles Enacted Legislation"</a>. <i>www.ncsl.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.ncsl.org&amp;rft.atitle=Autonomous+Vehicles+%7C+Self-Driving+Vehicles+Enacted+Legislation&amp;rft_id=http%3A%2F%2Fwww.ncsl.org%2Fresearch%2Ftransportation%2Fautonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r8
86058088"/></span>
</li>
<li id="cite_note-Call_for_debate_on_killer_robots-47"><span class="mw-cite-backlink">^ <a href="#cite_ref-Call_for_debate_on_killer_robots_47-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Call_for_debate_on_killer_robots_47-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://news.bbc.co.uk/2/hi/technology/8182003.stm">Call for debate on killer robots</a>, By Jason Palmer, Science and technology reporter, BBC News, 8/3/09.</span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.wired.com/dangerroom/2009/08/robot-three-way-portends-autonomous-future/">Robot Three-Way Portends Autonomous Future</a>, By David Axe wired.com, August 13, 2009.</span>
</li>
<li id="cite_note-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-49">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm">New Navy-funded Report Warns of War Robots Going "Terminator"</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20090728101106/http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm">Archived</a> 2009-07-28 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, by Jason Mick (Blog), dailytech.com, February 17, 2009.</span>
</li>
<li id="cite_note-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-50">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.engadget.com/2009/02/18/navy-report-warns-of-robot-uprising-suggests-a-strong-moral-com/">Navy report warns of robot uprising, suggests a strong moral compass</a>, by Joseph L. Flatley engadget.com, Feb 18th 2009.</span>
</li>
<li id="cite_note-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-51">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external free" href="https://search.proquest.com/docview/1372020233">https://search.proquest.com/docview/1372020233</a></span>
</li>
<li id="cite_note-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-52">^</a></b></span> <span class="reference-text"><cite class="citation web">Mitra, Ambarish. <a rel="nofollow" class="external text" href="https://qz.com/1244055/we-can-train-ai-to-identify-good-and-evil-and-then-use-it-to-teach-us-morality/">"We can train AI to identify good and evil, and then use it to teach us morality"</a>. <i>Quartz</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Quartz&amp;rft.atitle=We+can+train+AI+to+identify+good+and+evil%2C+and+then+use+it+to+teach+us+morality&amp;rft.aulast=Mitra&amp;rft.aufirst=Ambarish&amp;rft_id=https%3A%2F%2Fqz.com%2F1244055%2Fwe-can-train-ai-to-identify-good-and-evil-and-then-use-it-to-teach-us-morality%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link
 rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-53">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://futureoflife.org/ai-principles/">"AI Principles"</a>. <i>Future of Life Institute</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-26</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Future+of+Life+Institute&amp;rft.atitle=AI+Principles&amp;rft_id=https%3A%2F%2Ffutureoflife.org%2Fai-principles%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-theatlantic.com-54"><span class="mw-cite-backlink">^ <a href="#cite_ref-theatlantic.com_54-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-theatlantic.com_54-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation web">Zach Musgrave and Bryan W. Roberts (2015-08-14). <a rel="nofollow" class="external text" href="https://www.theatlantic.com/technology/archive/2015/08/humans-not-robots-are-the-real-reason-artificial-intelligence-is-scary/400994/">"Why Artificial Intelligence Can Too Easily Be Weaponized - The Atlantic"</a>. <i>The Atlantic</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Atlantic&amp;rft.atitle=Why+Artificial+Intelligence+Can+Too+Easily+Be+Weaponized+-+The+Atlantic&amp;rft.date=2015-08-14&amp;rft.au=Zach+Musgrave+and+Bryan+W.+Roberts&amp;rft_id=https%3A%2F%2Fwww.theatlantic.com%2Ftechnology%2Farchive%2F2015%2F08%2Fhumans-not-robots-are-the-real-re
ason-artificial-intelligence-is-scary%2F400994%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55">^</a></b></span> <span class="reference-text"><cite class="citation web">Cat Zakrzewski (2015-07-27). <a rel="nofollow" class="external text" href="https://blogs.wsj.com/digits/2015/07/27/musk-hawking-warn-of-artificial-intelligence-weapons/">"Musk, Hawking Warn of Artificial Intelligence Weapons"</a>. <i>WSJ</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=WSJ&amp;rft.atitle=Musk%2C+Hawking+Warn+of+Artificial+Intelligence+Weapons&amp;rft.date=2015-07-27&amp;rft.au=Cat+Zakrzewski&amp;rft_id=https%3A%2F%2Fblogs.wsj.com%2Fdigits%2F2015%2F07%2F27%2Fmusk-hawking-warn-of-artificial-intelligence-weapons%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-givewell-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-givewell_56-0">^</a></b></span> <span class="reference-text"><cite class="citation report"><a href="/wiki/GiveWell" title="GiveWell">GiveWell</a> (2015). <a rel="nofollow" class="external text" href="http://www.givewell.org/labs/causes/ai-risk">Potential risks from advanced artificial intelligence</a> (Report)<span class="reference-accessdate">. Retrieved <span class="nowrap">11 October</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Potential+risks+from+advanced+artificial+intelligence&amp;rft.date=2015&amp;rft.au=GiveWell&amp;rft_id=http%3A%2F%2Fwww.givewell.org%2Flabs%2Fcauses%2Fai-risk&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Andersonweb-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-Andersonweb_57-0">^</a></b></span> <span class="reference-text"><cite class="citation web">Anderson. <a rel="nofollow" class="external text" href="http://uhaweb.hartford.edu/anderson/MachineEthics.html">"Machine Ethics"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">27 June</span> 2011</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Machine+Ethics&amp;rft.au=Anderson&amp;rft_id=http%3A%2F%2Fuhaweb.hartford.edu%2Fanderson%2FMachineEthics.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Anderson2011-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-Anderson2011_58-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFAndersonAnderson2011" class="citation book">Anderson, Michael; Anderson, Susan Leigh, eds. (July 2011). <i>Machine Ethics</i>. <a href="/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-521-11235-2" title="Special:BookSources/978-0-521-11235-2"><bdi>978-0-521-11235-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Machine+Ethics&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2011-07&amp;rft.isbn=978-0-521-11235-2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href
="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Anderson2006-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-Anderson2006_59-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Anderson, Michael; Anderson, Susan Leigh, eds. (July–August 2006). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20111126025029/http://www.computer.org/portal/web/csdl/abs/mags/ex/2006/04/x4toc.htm">"Special Issue on Machine Ethics"</a>. <i>IEEE Intelligent Systems</i>. <b>21</b> (4): 10–63. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2Fmis.2006.70">10.1109/mis.2006.70</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/1541-1672">1541-1672</a>. Archived from <a rel="nofollow" class="external text" href="http://www.computer.org/portal/web/csdl/abs/mags/ex/2006/04
/x4toc.htm">the original</a> on 2011-11-26.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Intelligent+Systems&amp;rft.atitle=Special+Issue+on+Machine+Ethics&amp;rft.volume=21&amp;rft.issue=4&amp;rft.pages=10-63&amp;rft.date=2006-07%2F2006-08&amp;rft_id=info%3Adoi%2F10.1109%2Fmis.2006.70&amp;rft.issn=1541-1672&amp;rft_id=http%3A%2F%2Fwww.computer.org%2Fportal%2Fweb%2Fcsdl%2Fabs%2Fmags%2Fex%2F2006%2F04%2Fx4toc.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Anderson2007-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-Anderson2007_60-0">^</a></b></span> <span class="reference-text"><cite class="citation journal">Anderson, Michael; Anderson, Susan Leigh (Winter 2007). <a rel="nofollow" class="external text" href="http://www.aaai.org/ojs/index.php/aimagazine/article/view/2065">"Machine Ethics: Creating an Ethical Intelligent Agent"</a>. <i>AI Magazine</i>. <b>28</b> (4): 15–26. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0738-4602">0738-4602</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=AI+Magazine&amp;rft.atitle=Machine+Ethics%3A+Creating+an+Ethical+Intelligent+Agent&amp;rft.ssn=winter&amp;rft.volume=28&amp;rft.issue=4&amp;rft.pages=15-26&amp;rft.date=2007&amp;rft.issn=0738-4602&amp;rft.aulast=Anderson&amp;rft.a
ufirst=Michael&amp;rft.au=Anderson%2C+Susan+Leigh&amp;rft_id=http%3A%2F%2Fwww.aaai.org%2Fojs%2Findex.php%2Faimagazine%2Farticle%2Fview%2F2065&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-61">^</a></b></span> <span class="reference-text"><cite class="citation journal">Boyles, Robert James M. (October 2017). <a rel="nofollow" class="external text" href="https://philpapers.org/archive/BOYPSF.pdf">"Philosophical Signposts for Artificial Moral Agent Frameworks"</a> <span class="cs1-format">(PDF)</span>. <i>Suri</i>. <b>6</b> (2): 92–109.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Suri&amp;rft.atitle=Philosophical+Signposts+for+Artificial+Moral+Agent+Frameworks&amp;rft.volume=6&amp;rft.issue=2&amp;rft.pages=92-109&amp;rft.date=2017-10&amp;rft.aulast=Boyles&amp;rft.aufirst=Robert+James+M.&amp;rft_id=https%3A%2F%2Fphilpapers.org%2Farchive%2FBOYPSF.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Asimov2008-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-Asimov2008_62-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFAsimov2008" class="citation book">Asimov, Isaac (2008). <a href="/wiki/I,_Robot" title="I, Robot"><i>I, Robot</i></a>. New York: Bantam. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-553-38256-3" title="Special:BookSources/978-0-553-38256-3"><bdi>978-0-553-38256-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=I%2C+Robot&amp;rft.place=New+York&amp;rft.pub=Bantam&amp;rft.date=2008&amp;rft.isbn=978-0-553-38256-3&amp;rft.aulast=Asimov&amp;rft.aufirst=Isaac&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-lacuna-63"><span class="mw-cite-backlink"><b><a href="#cite_ref-lacuna_63-0">^</a></b></span> <span class="reference-text"><cite id="lacuna" class="citation journal">Bryson, Joanna; Diamantis, Mihailis; Grant, Thomas (September 2017). "Of, for, and by the people: the legal lacuna of synthetic persons". <i>Artificial Intelligence and Law</i>. <b>25</b> (3): 273–291. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1007%2Fs10506-017-9214-9">10.1007/s10506-017-9214-9</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence+and+Law&amp;rft.atitle=Of%2C+for%2C+and+by+the+people%3A+the+legal+lacuna+of+synthetic+persons&amp;rft.volume=25&amp;rft.issue=3&amp;rft.pages=273-291&amp;rft.date=2017-09&amp;rft_id=info%3Adoi%2F10.1007%2Fs10506-017-9214-9&amp;rft.aulast=Bryson&amp;rft.aufirst=Joanna&amp;rft.au=D
iamantis%2C+Mihailis&amp;rft.au=Grant%2C+Thomas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-principles-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-principles_64-0">^</a></b></span> <span class="reference-text"><cite id="principles" class="citation web"><a rel="nofollow" class="external text" href="https://epsrc.ukri.org/research/ourportfolio/themes/engineering/activities/principlesofrobotics/">"Principles of robotics"</a>. UK's EPSRC. September 2010<span class="reference-accessdate">. Retrieved <span class="nowrap">10 January</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Principles+of+robotics&amp;rft.pub=UK%27s+EPSRC&amp;rft.date=2010-09&amp;rft_id=https%3A%2F%2Fepsrc.ukri.org%2Fresearch%2Fourportfolio%2Fthemes%2Fengineering%2Factivities%2Fprinciplesofrobotics%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-65"><span class="mw-cite-backlink"><b><a href="#cite_ref-65">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.popsci.com/scitech/article/2009-08/evolving-robots-learn-lie-hide-resources-each-other">Evolving Robots Learn To Lie To Each Other</a>, Popular Science, August 18, 2009</span>
</li>
<li id="cite_note-SantosLang2002-66"><span class="mw-cite-backlink">^ <a href="#cite_ref-SantosLang2002_66-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-SantosLang2002_66-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation web">Santos-Lang, Chris (2002). <a rel="nofollow" class="external text" href="http://santoslang.wordpress.com/article/ethics-for-artificial-intelligences-3iue30fi4gfq9-1">"Ethics for Artificial Intelligences"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Ethics+for+Artificial+Intelligences&amp;rft.date=2002&amp;rft.aulast=Santos-Lang&amp;rft.aufirst=Chris&amp;rft_id=http%3A%2F%2Fsantoslang.wordpress.com%2Farticle%2Fethics-for-artificial-intelligences-3iue30fi4gfq9-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-67">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm">Science New Navy-funded Report Warns of War Robots Going "Terminator"</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20090728101106/http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm">Archived</a> 2009-07-28 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, by Jason Mick (Blog), dailytech.com, February 17, 2009.</span>
</li>
<li id="cite_note-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-68">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.engadget.com/2009/02/18/navy-report-warns-of-robot-uprising-suggests-a-strong-moral-com/">Navy report warns of robot uprising, suggests a strong moral compass</a>, by Joseph L. Flatley  engadget.com, Feb 18th 2009.</span>
</li>
<li id="cite_note-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-69">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm">AAAI Presidential Panel on Long-Term AI Futures 2008-2009 Study</a>, Association for the Advancement of Artificial Intelligence, Accessed 7/26/09.</span>
</li>
<li id="cite_note-nytimes_july09-70"><span class="mw-cite-backlink">^ <a href="#cite_ref-nytimes_july09_70-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-nytimes_july09_70-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.nytimes.com/2009/07/26/science/26robot.html?_r=1&amp;ref=todayspaper">Scientists Worry Machines May Outsmart Man</a> By JOHN MARKOFF, NY Times, July 26, 2009.</span>
</li>
<li id="cite_note-71"><span class="mw-cite-backlink"><b><a href="#cite_ref-71">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">The Coming Technological Singularity: How to Survive in the Post-Human Era</a>, by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.</span>
</li>
<li id="cite_note-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-72">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html">Article at Asimovlaws.com</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120524150856/http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html">Archived</a> May 24, 2012, at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, July 2004, accessed 7/27/09.</span>
</li>
<li id="cite_note-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-73">^</a></b></span> <span class="reference-text"><cite class="citation news">Al-Rodhan, Nayef (2015-08-12). <a rel="nofollow" class="external text" href="https://www.foreignaffairs.com/articles/2015-08-12/moral-code">"The Moral Code"</a>. <i>Foreign Affairs</i>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0015-7120">0015-7120</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2018-01-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Foreign+Affairs&amp;rft.atitle=The+Moral+Code&amp;rft.date=2015-08-12&amp;rft.issn=0015-7120&amp;rft.aulast=Al-Rodhan&amp;rft.aufirst=Nayef&amp;rft_id=https%3A%2F%2Fwww.foreignaffairs.com%2Farticles%2F2015-08-12%2Fmoral-code&amp;rfr_id=info%3Asid%2Fen.wi
kipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Wallach2008-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-Wallach2008_74-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFWallachAllen2008" class="citation book">Wallach, Wendell; Allen, Colin (November 2008). <i>Moral Machines: Teaching Robots Right from Wrong</i>. USA: <a href="/wiki/Oxford_University_Press" title="Oxford University Press">Oxford University Press</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-19-537404-9" title="Special:BookSources/978-0-19-537404-9"><bdi>978-0-19-537404-9</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Moral+Machines%3A+Teaching+Robots+Right+from+Wrong&amp;rft.place=USA&amp;rft.pub=Oxford+University+Press&amp;rft.date=2008-11&amp;rft.isbn=978-0-19-537404-9&amp;rft.aulast=Wallach&amp;rft.aufirst=Wendell&amp;rft.au=Allen%2C+Colin&amp;rfr_
id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-75"><span class="mw-cite-backlink"><b><a href="#cite_ref-75">^</a></b></span> <span class="reference-text"><cite class="citation web"><a href="/wiki/Nick_Bostrom" title="Nick Bostrom">Bostrom, Nick</a>; <a href="/wiki/Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Yudkowsky, Eliezer</a> (2011). <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/artificial-intelligence.pdf">"The Ethics of Artificial Intelligence"</a> <span class="cs1-format">(PDF)</span>. <i>Cambridge Handbook of Artificial Intelligence</i>. <a href="/wiki/Cambridge_Press" class="mw-redirect" title="Cambridge Press">Cambridge Press</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Cambridge+Handbook+of+Artificial+Intelligence&amp;rft.atitle=The+Ethics+of+Artificial+Intelligence&amp;rft.date=2011&amp;rft.aulast=Bostrom&amp;rft.aufirst=Nick&amp;rft.au=Yudkowsky%2C+Eliezer&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2
Fethics%2Fartificial-intelligence.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-76">^</a></b></span> <span class="reference-text"><cite class="citation web">Howard, Ayanna. <a rel="nofollow" class="external text" href="https://sloanreview.mit.edu/article/the-regulation-of-ai-should-organizations-be-worried/">"The Regulation of AI – Should Organizations Be Worried? | Ayanna Howard"</a>. <i>MIT Sloan Management Review</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-08-14</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Sloan+Management+Review&amp;rft.atitle=The+Regulation+of+AI+%E2%80%93+Should+Organizations+Be+Worried%3F+%7C+Ayanna+Howard&amp;rft.aulast=Howard&amp;rft.aufirst=Ayanna&amp;rft_id=https%3A%2F%2Fsloanreview.mit.edu%2Farticle%2Fthe-regulation-of-ai-should-organizations-be-worried%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></
span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Muehlhauser,_Luke_2012-77"><span class="mw-cite-backlink">^ <a href="#cite_ref-Muehlhauser,_Luke_2012_77-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Muehlhauser,_Luke_2012_77-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Muehlhauser, Luke, and Louie Helm. 2012. <a rel="nofollow" class="external text" href="https://intelligence.org/files/IE-ME.pdf">"Intelligence Explosion and Machine Ethics"</a>. In Singularity Hypotheses: A Scientific and Philosophical Assessment, edited by Amnon Eden, Johnny Søraker, James H. Moor, and Eric Steinhart. Berlin: Springer.</span>
</li>
<li id="cite_note-Bostrom,_Nick_2003-78"><span class="mw-cite-backlink">^ <a href="#cite_ref-Bostrom,_Nick_2003_78-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Bostrom,_Nick_2003_78-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Bostrom, Nick. 2003. <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/ai.html">"Ethical Issues in Advanced Artificial Intelligence"</a>. In Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, edited by Iva Smit and George E. Lasker, 12–17. Vol. 2. Windsor, ON: International Institute for Advanced Studies in Systems Research / Cybernetics.</span>
</li>
<li id="cite_note-79"><span class="mw-cite-backlink"><b><a href="#cite_ref-79">^</a></b></span> <span class="reference-text"><cite class="citation journal"><a rel="nofollow" class="external text" href="https://www.wired.com/2014/12/armageddon-is-not-the-ai-problem/">"Sure, Artificial Intelligence May End Our World, But That Is Not the Main Problem"</a>. <i>WIRED</i>. 2014-12-04<span class="reference-accessdate">. Retrieved <span class="nowrap">2015-11-04</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=WIRED&amp;rft.atitle=Sure%2C+Artificial+Intelligence+May+End+Our+World%2C+But+That+Is+Not+the+Main+Problem&amp;rft.date=2014-12-04&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2014%2F12%2Farmageddon-is-not-the-ai-problem%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-80">^</a></b></span> <span class="reference-text">Yudkowsky, Eliezer. 2011. <a rel="nofollow" class="external text" href="https://intelligence.org/files/ComplexValues.pdf">"Complex Value Systems in Friendly AI"</a>. In Schmidhuber, Thórisson, and Looks 2011, 388–393.</span>
</li>
<li id="cite_note-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-81">^</a></b></span> <span class="reference-text">"Partnership on Artificial Intelligence to Benefit People and Society". N.p., n.d. 24 October 2016.</span>
</li>
<li id="cite_note-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-82">^</a></b></span> <span class="reference-text">Fiegerman, Seth. "Facebook, Google, Amazon Create Group to Ease AI Concerns". CNNMoney. n.d. 4 December 2016.</span>
</li>
<li id="cite_note-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-83">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.hpcwire.com/2019/05/14/ccc-offers-draft-20-year-ai-roadmap-seeks-comments/">"CCC Offers Draft 20-Year AI Roadmap; Seeks Comments"</a>. <i>HPCwire</i>. 2019-05-14<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=HPCwire&amp;rft.atitle=CCC+Offers+Draft+20-Year+AI+Roadmap%3B+Seeks+Comments&amp;rft.date=2019-05-14&amp;rft_id=https%3A%2F%2Fwww.hpcwire.com%2F2019%2F05%2F14%2Fccc-offers-draft-20-year-ai-roadmap-seeks-comments%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-84">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.cccblog.org/2019/05/13/request-comments-on-draft-a-20-year-community-roadmap-for-ai-research-in-the-us/">"Request Comments on Draft: A 20-Year Community Roadmap for AI Research in the US&#160;» CCC Blog"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-07-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Request+Comments+on+Draft%3A+A+20-Year+Community+Roadmap+for+AI+Research+in+the+US+%C2%BB+CCC+Blog&amp;rft_id=https%3A%2F%2Fwww.cccblog.org%2F2019%2F05%2F13%2Frequest-comments-on-draft-a-20-year-community-roadmap-for-ai-research-in-the-us%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" hr
ef="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-85"><span class="mw-cite-backlink"><b><a href="#cite_ref-85">^</a></b></span> <span class="reference-text"><cite class="citation book">Müller, Vincent C. (2016). <a rel="nofollow" class="external text" href="http://philpapers.org/rec/MLLROA-3"><i>Risks of artificial intelligence</i></a>. CRC Press - Chapman &amp; Hall.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Risks+of+artificial+intelligence&amp;rft.pub=CRC+Press+-+Chapman+%26+Hall&amp;rft.date=2016&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Vincent+C.&amp;rft_id=http%3A%2F%2Fphilpapers.org%2Frec%2FMLLROA-3&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=15" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="http://www.nature.com/news/robotics-ethics-of-artificial-intelligence-1.17611">Robotics: Ethics of artificial intelligence</a>. "Four leading researchers share their concerns and solutions for reducing societal risks from intelligent machines." <i><a href="/wiki/Nature_(journal)" title="Nature (journal)">Nature</a>,</i>     521,    415–418    (28 May 2015)    doi:10.1038/521415a</li>
<li><a rel="nofollow" class="external text" href="http://news.bbc.co.uk/1/hi/sci/tech/1809769.stm">BBC News: Games to take on a life of their own</a></li>
<li><a rel="nofollow" class="external text" href="http://www.dasboot.org/thorisson.htm">Who's Afraid of Robots?</a>, an article on humanity's fear of artificial intelligence.</li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080418122849/http://www.southernct.edu/organizations/rccs/resources/research/introduction/bynum_shrt_hist.html">A short history of computer ethics</a></li>
<li><a rel="nofollow" class="external text" href="https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/">AI Ethics Guidelines Global Inventory</a> by <a rel="nofollow" class="external text" href="https://algorithmwatch.org">Algorithmwatch</a></li></ul>
<div role="navigation" class="navbox" aria-labelledby="Philosophy_of_science" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Philosophy_of_science" title="Template:Philosophy of science"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Philosophy_of_science" title="Template talk:Philosophy of science"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Philosophy
_of_science&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Philosophy_of_science" style="font-size:114%;margin:0 4em"><a href="/wiki/Philosophy_of_science" title="Philosophy of science">Philosophy of science</a></div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:7.5em">Concepts</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Philosophical_analysis" title="Philosophical analysis">Analysis</a></li>
<li><a href="/wiki/Analytic%E2%80%93synthetic_distinction" title="Analytic–synthetic distinction">Analytic–synthetic distinction</a></li>
<li><a href="/wiki/A_priori_and_a_posteriori" title="A priori and a posteriori"><i>A priori</i> and <i>a posteriori</i></a></li>
<li><a href="/wiki/Causality" title="Causality">Causality</a></li>
<li><a href="/wiki/Commensurability_(philosophy_of_science)" title="Commensurability (philosophy of science)">Commensurability</a></li>
<li><a href="/wiki/Consilience" title="Consilience">Consilience</a></li>
<li><a href="/wiki/Construct_(philosophy)" title="Construct (philosophy)">Construct</a></li>
<li><a href="/wiki/Creative_synthesis" title="Creative synthesis">Creative synthesis</a></li>
<li><a href="/wiki/Demarcation_problem" title="Demarcation problem">Demarcation problem</a></li>
<li><a href="/wiki/Empirical_evidence" title="Empirical evidence">Empirical evidence</a></li>
<li><a href="/wiki/Explanatory_power" title="Explanatory power">Explanatory power</a></li>
<li><a href="/wiki/Fact" title="Fact">Fact</a></li>
<li><a href="/wiki/Falsifiability" title="Falsifiability">Falsifiability</a></li>
<li><a href="/wiki/Feminist_method" title="Feminist method">Feminist method</a></li>
<li><a href="/wiki/Functional_contextualism" title="Functional contextualism">Functional contextualism</a></li></ul>
<ul><li><i><a href="/wiki/Ignoramus_et_ignorabimus" title="Ignoramus et ignorabimus">Ignoramus et ignorabimus</a></i></li>
<li><a href="/wiki/Inductive_reasoning" title="Inductive reasoning">Inductive reasoning</a></li>
<li><a href="/wiki/Intertheoretic_reduction" title="Intertheoretic reduction">Intertheoretic reduction</a></li>
<li><a href="/wiki/Inquiry" title="Inquiry">Inquiry</a></li>
<li><a href="/wiki/Nature_(philosophy)" title="Nature (philosophy)">Nature</a></li>
<li><a href="/wiki/Objectivity_(philosophy)" title="Objectivity (philosophy)">Objectivity</a></li>
<li><a href="/wiki/Observation" title="Observation">Observation</a></li>
<li><a href="/wiki/Paradigm" title="Paradigm">Paradigm</a></li>
<li><a href="/wiki/Problem_of_induction" title="Problem of induction">Problem of induction</a></li>
<li><a href="/wiki/Scientific_law" title="Scientific law">Scientific law</a></li>
<li><a href="/wiki/Scientific_method" title="Scientific method">Scientific method</a></li>
<li><a href="/wiki/Scientific_revolution" class="mw-redirect" title="Scientific revolution">Scientific revolution</a></li>
<li><a href="/wiki/Scientific_theory" title="Scientific theory">Scientific theory</a></li>
<li><a href="/wiki/Testability" title="Testability">Testability</a></li>
<li><a href="/wiki/Theory_choice" title="Theory choice">Theory choice</a></li>
<li><a href="/wiki/Theory-ladenness" title="Theory-ladenness">Theory-ladenness</a></li>
<li><a href="/wiki/Underdetermination" title="Underdetermination">Underdetermination</a></li>
<li><a href="/wiki/Unity_of_science" title="Unity of science">Unity of science</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em"><a href="/wiki/Category:Metatheory_of_science" title="Category:Metatheory of science">Metatheory<br />of science</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Coherentism" title="Coherentism">Coherentism</a></li>
<li><a href="/wiki/Confirmation_holism" title="Confirmation holism">Confirmation holism</a></li>
<li><a href="/wiki/Constructive_empiricism" title="Constructive empiricism">Constructive empiricism</a></li>
<li><a href="/wiki/Constructive_realism" title="Constructive realism">Constructive realism</a></li>
<li><a href="/wiki/Constructivist_epistemology" title="Constructivist epistemology">Constructivist epistemology</a></li>
<li><a href="/wiki/Contextualism" title="Contextualism">Contextualism</a></li>
<li><a href="/wiki/Conventionalism" title="Conventionalism">Conventionalism</a></li>
<li><a href="/wiki/Deductive-nomological_model" title="Deductive-nomological model">Deductive-nomological model</a></li>
<li><a href="/wiki/Hypothetico-deductive_model" title="Hypothetico-deductive model">Hypothetico-deductive model</a></li>
<li><a href="/wiki/Inductionism" title="Inductionism">Inductionism</a></li>
<li><a href="/wiki/Epistemological_anarchism" title="Epistemological anarchism">Epistemological anarchism</a></li>
<li><a href="/wiki/Evolutionism" title="Evolutionism">Evolutionism</a></li>
<li><a href="/wiki/Fallibilism" title="Fallibilism">Fallibilism</a></li>
<li><a href="/wiki/Foundationalism" title="Foundationalism">Foundationalism</a></li>
<li><a href="/wiki/Instrumentalism" title="Instrumentalism">Instrumentalism</a></li>
<li><a href="/wiki/Pragmatism" title="Pragmatism">Pragmatism</a></li>
<li><a href="/wiki/Model-dependent_realism" title="Model-dependent realism">Model-dependent realism</a></li>
<li><a href="/wiki/Naturalism_(philosophy)" title="Naturalism (philosophy)">Naturalism</a></li>
<li><a href="/wiki/Physicalism" title="Physicalism">Physicalism</a></li>
<li><a href="/wiki/Positivism" title="Positivism">Positivism</a>&#160;/&#32;<a href="/wiki/Reductionism" title="Reductionism">Reductionism</a>&#160;/&#32;<a href="/wiki/Determinism" title="Determinism">Determinism</a></li>
<li><a href="/wiki/Rationalism" title="Rationalism">Rationalism</a>&#160;/&#32;<a href="/wiki/Empiricism" title="Empiricism">Empiricism</a></li>
<li><a href="/wiki/Received_view_of_theories" title="Received view of theories">Received view</a>&#160;/&#32;<a href="/wiki/Semantic_view_of_theories" title="Semantic view of theories">Semantic view of theories</a></li>
<li><a href="/wiki/Scientific_realism" title="Scientific realism">Scientific realism</a>&#160;/&#32;<a href="/wiki/Anti-realism" title="Anti-realism">Anti-realism</a></li>
<li><a href="/wiki/Scientific_essentialism" title="Scientific essentialism">Scientific essentialism</a></li>
<li><a href="/wiki/Scientific_formalism" title="Scientific formalism">Scientific formalism</a></li>
<li><a href="/wiki/Scientific_skepticism" class="mw-redirect" title="Scientific skepticism">Scientific skepticism</a></li>
<li><a href="/wiki/Scientism" title="Scientism">Scientism</a></li>
<li><a href="/wiki/Structuralism_(philosophy_of_science)" title="Structuralism (philosophy of science)">Structuralism</a></li>
<li><a href="/wiki/Uniformitarianism" title="Uniformitarianism">Uniformitarianism</a></li>
<li><a href="/wiki/Vitalism" title="Vitalism">Vitalism</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em">Philosophy of</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Philosophy_of_physics" title="Philosophy of physics">Physics</a>
<ul><li><a href="/wiki/Philosophy_of_thermal_and_statistical_physics" title="Philosophy of thermal and statistical physics">thermal and statistical</a></li>
<li><a href="/wiki/Philosophy_of_motion" title="Philosophy of motion">Motion</a></li></ul></li>
<li><a href="/wiki/Philosophy_of_chemistry" title="Philosophy of chemistry">Chemistry</a></li>
<li><a href="/wiki/Philosophy_of_biology" title="Philosophy of biology">Biology</a></li>
<li><a href="/wiki/Philosophy_of_environment" title="Philosophy of environment">Environment</a></li>
<li><a href="/wiki/Philosophy_of_geography" title="Philosophy of geography">Geography</a></li>
<li><a href="/wiki/Philosophy_of_social_science" title="Philosophy of social science">Social science</a></li>
<li><a href="/wiki/Philosophy_of_technology" title="Philosophy of technology">Technology</a>
<ul><li><a href="/wiki/Philosophy_of_engineering" title="Philosophy of engineering">Engineering</a></li>
<li><a href="/wiki/Philosophy_of_artificial_intelligence" title="Philosophy of artificial intelligence">Artificial intelligence</a></li>
<li><a href="/wiki/Philosophy_of_computer_science" title="Philosophy of computer science">Computer science</a></li></ul></li>
<li><a href="/wiki/Philosophy_of_information" title="Philosophy of information">Information</a></li>
<li><a href="/wiki/Philosophy_of_mind" title="Philosophy of mind">Mind</a></li>
<li><a href="/wiki/Philosophy_of_psychiatry" title="Philosophy of psychiatry">Psychiatry</a></li>
<li><a href="/wiki/Philosophy_of_psychology" title="Philosophy of psychology">Psychology</a></li>
<li><a href="/wiki/Philosophy_of_perception" title="Philosophy of perception">Perception</a></li>
<li><a href="/wiki/Philosophy_of_space_and_time" title="Philosophy of space and time">Space and time</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em"><a href="/wiki/Index_of_philosophy_of_science_articles" title="Index of philosophy of science articles">Related topics</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Alchemy" title="Alchemy">Alchemy</a></li>
<li><a href="/wiki/Criticism_of_science" title="Criticism of science">Criticism of science</a></li>
<li><a href="/wiki/Epistemology" title="Epistemology">Epistemology</a></li>
<li><a href="/wiki/Faith_and_rationality" title="Faith and rationality">Faith and rationality</a></li>
<li><a href="/wiki/History_and_philosophy_of_science" title="History and philosophy of science">History and philosophy of science</a></li>
<li><a href="/wiki/History_of_science" title="History of science">History of science</a></li>
<li><a href="/wiki/History_of_evolutionary_thought" title="History of evolutionary thought">History of evolutionary thought</a></li>
<li><a href="/wiki/Logic" title="Logic">Logic</a></li>
<li><a href="/wiki/Metaphysics" title="Metaphysics">Metaphysics</a></li>
<li><a href="/wiki/Pseudoscience" title="Pseudoscience">Pseudoscience</a></li>
<li><a href="/wiki/Relationship_between_religion_and_science" title="Relationship between religion and science">Relationship between religion and science</a></li>
<li><a href="/wiki/Rhetoric_of_science" title="Rhetoric of science">Rhetoric of science</a></li>
<li><a href="/wiki/Science_studies" title="Science studies">Science studies</a></li>
<li><a href="/wiki/Sociology_of_scientific_knowledge" title="Sociology of scientific knowledge">Sociology of scientific knowledge</a></li>
<li><a href="/wiki/Sociology_of_scientific_ignorance" title="Sociology of scientific ignorance">Sociology of scientific ignorance</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks mw-collapsible mw-collapsed navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div id="Philosophers_of_science_by_era" style="font-size:114%;margin:0 4em"><a href="/wiki/List_of_philosophers_of_science" title="List of philosophers of science">Philosophers of science</a> by era</div></th></tr><tr><td colspan="2" class="navbox-list navbox-odd" style="width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:7.5em">Ancient</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Plato" title="Plato">Plato</a></li>
<li><a href="/wiki/Aristotle" title="Aristotle">Aristotle</a></li>
<li><a href="/wiki/Stoicism" title="Stoicism">Stoicism</a></li>
<li><a href="/wiki/Epicureanism" title="Epicureanism">Epicureans</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em">Medieval</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Averroes" title="Averroes">Averroes</a></li>
<li><a href="/wiki/Avicenna" title="Avicenna">Avicenna</a></li>
<li><a href="/wiki/Roger_Bacon" title="Roger Bacon">Roger Bacon</a></li>
<li><a href="/wiki/William_of_Ockham" title="William of Ockham">William of Ockham</a></li>
<li><a href="/wiki/Hugh_of_Saint_Victor" title="Hugh of Saint Victor">Hugh of Saint Victor</a></li>
<li><a href="/wiki/Dominicus_Gundissalinus" title="Dominicus Gundissalinus">Dominicus Gundissalinus</a></li>
<li><a href="/wiki/Robert_Kilwardby" title="Robert Kilwardby">Robert Kilwardby</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em">Early modern</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Francis_Bacon" title="Francis Bacon">Francis Bacon</a></li>
<li><a href="/wiki/Thomas_Hobbes" title="Thomas Hobbes">Thomas Hobbes</a></li>
<li><a href="/wiki/Ren%C3%A9_Descartes" title="René Descartes">René Descartes</a></li>
<li><a href="/wiki/Galileo_Galilei" title="Galileo Galilei">Galileo Galilei</a></li>
<li><a href="/wiki/Pierre_Gassendi" title="Pierre Gassendi">Pierre Gassendi</a></li>
<li><a href="/wiki/Isaac_Newton" title="Isaac Newton">Isaac Newton</a></li>
<li><a href="/wiki/David_Hume" title="David Hume">David Hume</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em">Late modern</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Immanuel_Kant" title="Immanuel Kant">Immanuel Kant</a></li>
<li><a href="/wiki/Friedrich_Wilhelm_Joseph_Schelling" title="Friedrich Wilhelm Joseph Schelling">Friedrich Schelling</a></li>
<li><a href="/wiki/William_Whewell" title="William Whewell">William Whewell</a></li>
<li><a href="/wiki/Auguste_Comte" title="Auguste Comte">Auguste Comte</a></li>
<li><a href="/wiki/John_Stuart_Mill" title="John Stuart Mill">John Stuart Mill</a></li>
<li><a href="/wiki/Herbert_Spencer" title="Herbert Spencer">Herbert Spencer</a></li>
<li><a href="/wiki/Wilhelm_Wundt" title="Wilhelm Wundt">Wilhelm Wundt</a></li>
<li><a href="/wiki/Charles_Sanders_Peirce" title="Charles Sanders Peirce">Charles Sanders Peirce</a></li>
<li><a href="/wiki/Wilhelm_Windelband" title="Wilhelm Windelband">Wilhelm Windelband</a></li>
<li><a href="/wiki/Henri_Poincar%C3%A9" title="Henri Poincaré">Henri Poincaré</a></li>
<li><a href="/wiki/Pierre_Duhem" title="Pierre Duhem">Pierre Duhem</a></li>
<li><a href="/wiki/Rudolf_Steiner" title="Rudolf Steiner">Rudolf Steiner</a></li>
<li><a href="/wiki/Karl_Pearson" title="Karl Pearson">Karl Pearson</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:7.5em">Contemporary</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Alfred_North_Whitehead" title="Alfred North Whitehead">Alfred North Whitehead</a></li>
<li><a href="/wiki/Bertrand_Russell" title="Bertrand Russell">Bertrand Russell</a></li>
<li><a href="/wiki/Albert_Einstein" title="Albert Einstein">Albert Einstein</a></li>
<li><a href="/wiki/Otto_Neurath" title="Otto Neurath">Otto Neurath</a></li>
<li><a href="/wiki/C._D._Broad" title="C. D. Broad">C. D. Broad</a></li>
<li><a href="/wiki/Michael_Polanyi" title="Michael Polanyi">Michael Polanyi</a></li>
<li><a href="/wiki/Hans_Reichenbach" title="Hans Reichenbach">Hans Reichenbach</a></li>
<li><a href="/wiki/Rudolf_Carnap" title="Rudolf Carnap">Rudolf Carnap</a></li>
<li><a href="/wiki/Karl_Popper" title="Karl Popper">Karl Popper</a></li>
<li><a href="/wiki/Carl_Gustav_Hempel" title="Carl Gustav Hempel">Carl Gustav Hempel</a></li>
<li><a href="/wiki/Willard_Van_Orman_Quine" title="Willard Van Orman Quine">W. V. O. Quine</a></li>
<li><a href="/wiki/Thomas_Kuhn" title="Thomas Kuhn">Thomas Kuhn</a></li>
<li><a href="/wiki/Imre_Lakatos" title="Imre Lakatos">Imre Lakatos</a></li>
<li><a href="/wiki/Paul_Feyerabend" title="Paul Feyerabend">Paul Feyerabend</a></li>
<li><a href="/wiki/J%C3%BCrgen_Habermas" title="Jürgen Habermas">Jürgen Habermas</a></li>
<li><a href="/wiki/Ian_Hacking" title="Ian Hacking">Ian Hacking</a></li>
<li><a href="/wiki/Bas_van_Fraassen" title="Bas van Fraassen">Bas van Fraassen</a></li>
<li><a href="/wiki/Larry_Laudan" title="Larry Laudan">Larry Laudan</a></li>
<li><a href="/wiki/Daniel_Dennett" title="Daniel Dennett">Daniel Dennett</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><a href="/wiki/Category:Philosophy_of_science" title="Category:Philosophy of science">Category</a></li>
<li><a href="/wiki/File:Socrates.png" class="image"><img alt="Socrates.png" src="//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/18px-Socrates.png" decoding="async" width="18" height="28" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/27px-Socrates.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/36px-Socrates.png 2x" data-file-width="326" data-file-height="500" /></a> <a href="/wiki/Portal:Philosophy" title="Portal:Philosophy">Philosophy&#32;portal</a></li>
<li><a href="/wiki/File:Nuvola_apps_kalzium.svg" class="image"><img alt="Nuvola apps kalzium.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/28px-Nuvola_apps_kalzium.svg.png" decoding="async" width="28" height="28" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/42px-Nuvola_apps_kalzium.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/56px-Nuvola_apps_kalzium.svg.png 2x" data-file-width="128" data-file-height="128" /></a> <a href="/wiki/Portal:Science" title="Portal:Science">Science&#32;portal</a></li></ul>
</div></td></tr></tbody></table></div>
<div role="navigation" class="navbox" aria-labelledby="Ethics" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Ethics" title="Template:Ethics"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Ethics" title="Template talk:Ethics"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Ethics&amp;action=edit"><abbr title="Edit this template" style=";;background:none tra
nsparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Ethics" style="font-size:114%;margin:0 4em"><a href="/wiki/Ethics" title="Ethics">Ethics</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%">Theories</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Casuistry" title="Casuistry">Casuistry</a></li>
<li><a href="/wiki/Consequentialism" title="Consequentialism">Consequentialism</a></li>
<li><a href="/wiki/Deontological_ethics" title="Deontological ethics">Deontology</a>
<ul><li><a href="/wiki/Kantian_ethics" title="Kantian ethics">Kantian ethics</a></li></ul></li>
<li><a href="/wiki/Ethics_of_care" title="Ethics of care">Ethics of care</a></li>
<li><a href="/wiki/Existentialism" title="Existentialism">Existentialist ethics</a></li>
<li><a href="/wiki/Meta-ethics" title="Meta-ethics">Meta-ethics</a></li>
<li><a href="/wiki/Moral_particularism" title="Moral particularism">Particularism</a></li>
<li><a href="/wiki/Pragmatic_ethics" title="Pragmatic ethics">Pragmatic ethics</a></li>
<li><a href="/wiki/Role_ethics" title="Role ethics">Role ethics</a></li>
<li><a href="/wiki/Virtue_ethics" title="Virtue ethics">Virtue ethics</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Concepts</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Autonomy" title="Autonomy">Autonomy</a></li>
<li><a href="/wiki/Axiology" title="Axiology">Axiology</a></li>
<li><a href="/wiki/Belief" title="Belief">Belief</a></li>
<li><a href="/wiki/Conscience" title="Conscience">Conscience</a></li>
<li><a href="/wiki/Consent" title="Consent">Consent</a></li>
<li><a href="/wiki/Egalitarianism" title="Egalitarianism">Equality</a></li>
<li><a href="/wiki/Ethics_of_care" title="Ethics of care">Care</a></li>
<li><a href="/wiki/Free_will" title="Free will">Free will</a></li>
<li><a href="/wiki/Good_and_evil" title="Good and evil">Good and evil</a>
<ul><li><a href="/wiki/Good" title="Good">Good</a></li>
<li><a href="/wiki/Evil" title="Evil">Evil</a></li></ul></li>
<li><a href="/wiki/Happiness" title="Happiness">Happiness</a></li>
<li><a href="/wiki/Ideal_(ethics)" title="Ideal (ethics)">Ideal</a></li>
<li><a href="/wiki/Immorality" title="Immorality">Immorality</a></li>
<li><a href="/wiki/Justice" title="Justice">Justice</a></li>
<li><a href="/wiki/Liberty" title="Liberty">Liberty</a></li>
<li><a href="/wiki/Morality" title="Morality">Morality</a></li>
<li><a href="/wiki/Norm_(philosophy)" title="Norm (philosophy)">Norm</a></li>
<li><a href="/wiki/Political_freedom" title="Political freedom">Freedom</a></li>
<li><a href="/wiki/Principle" title="Principle">Principles</a></li>
<li><a href="/wiki/Suffering" title="Suffering">Suffering or Pain</a></li>
<li><a href="/wiki/Stewardship" title="Stewardship">Stewardship</a></li>
<li><a href="/wiki/Sympathy" title="Sympathy">Sympathy</a></li>
<li><a href="/wiki/Trust_(emotion)" class="mw-redirect" title="Trust (emotion)">Trust</a></li>
<li><a href="/wiki/Value_(ethics)" title="Value (ethics)">Value</a></li>
<li><a href="/wiki/Virtue" title="Virtue">Virtue</a></li>
<li><a href="/wiki/World_view" title="World view">World view</a></li>
<li><a href="/wiki/Wrongdoing" title="Wrongdoing">Wrong</a></li>
<li><b><a href="/wiki/Index_of_ethics_articles" title="Index of ethics articles">full index...</a></b></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Philosophers</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Laozi" title="Laozi">Laozi</a></li>
<li><a href="/wiki/Socrates" title="Socrates">Socrates</a></li>
<li><a href="/wiki/Plato" title="Plato">Plato</a></li>
<li><a href="/wiki/Aristotle" title="Aristotle">Aristotle</a></li>
<li><a href="/wiki/Diogenes" title="Diogenes">Diogenes</a></li>
<li><a href="/wiki/Valluvar" class="mw-redirect" title="Valluvar">Valluvar</a></li>
<li><a href="/wiki/Cicero" title="Cicero">Cicero</a></li>
<li><a href="/wiki/Confucius" title="Confucius">Confucius</a></li>
<li><a href="/wiki/Augustine_of_Hippo" title="Augustine of Hippo">Augustine of Hippo</a></li>
<li><a href="/wiki/Mencius" title="Mencius">Mencius</a></li>
<li><a href="/wiki/Mozi" title="Mozi">Mozi</a></li>
<li><a href="/wiki/Xun_Kuang" title="Xun Kuang">Xunzi</a></li>
<li><a href="/wiki/Thomas_Aquinas" title="Thomas Aquinas">Thomas Aquinas</a></li>
<li><a href="/wiki/Baruch_Spinoza" title="Baruch Spinoza">Baruch Spinoza</a></li>
<li><a href="/wiki/David_Hume" title="David Hume">David Hume</a></li>
<li><a href="/wiki/Immanuel_Kant" title="Immanuel Kant">Immanuel Kant</a></li>
<li><a href="/wiki/Georg_Wilhelm_Friedrich_Hegel" title="Georg Wilhelm Friedrich Hegel">Georg W. F. Hegel</a></li>
<li><a href="/wiki/Arthur_Schopenhauer" title="Arthur Schopenhauer">Arthur Schopenhauer</a></li>
<li><a href="/wiki/Jeremy_Bentham" title="Jeremy Bentham">Jeremy Bentham</a></li>
<li><a href="/wiki/John_Stuart_Mill" title="John Stuart Mill">John Stuart Mill</a></li>
<li><a href="/wiki/S%C3%B8ren_Kierkegaard" title="Søren Kierkegaard">Søren Kierkegaard</a></li>
<li><a href="/wiki/Henry_Sidgwick" title="Henry Sidgwick">Henry Sidgwick</a></li>
<li><a href="/wiki/Friedrich_Nietzsche" title="Friedrich Nietzsche">Friedrich Nietzsche</a></li>
<li><a href="/wiki/G._E._Moore" title="G. E. Moore">G. E. Moore</a></li>
<li><a href="/wiki/Karl_Barth" title="Karl Barth">Karl Barth</a></li>
<li><a href="/wiki/Paul_Tillich" title="Paul Tillich">Paul Tillich</a></li>
<li><a href="/wiki/Dietrich_Bonhoeffer" title="Dietrich Bonhoeffer">Dietrich Bonhoeffer</a></li>
<li><a href="/wiki/Philippa_Foot" title="Philippa Foot">Philippa Foot</a></li>
<li><a href="/wiki/John_Rawls" title="John Rawls">John Rawls</a></li>
<li><a href="/wiki/John_Dewey" title="John Dewey">John Dewey</a></li>
<li><a href="/wiki/Bernard_Williams" title="Bernard Williams">Bernard Williams</a></li>
<li><a href="/wiki/J._L._Mackie" title="J. L. Mackie">J. L. Mackie</a></li>
<li><a href="/wiki/G._E._M._Anscombe" title="G. E. M. Anscombe">G. E. M. Anscombe</a></li>
<li><a href="/wiki/William_Frankena" title="William Frankena">William Frankena</a></li>
<li><a href="/wiki/Alasdair_MacIntyre" title="Alasdair MacIntyre">Alasdair MacIntyre</a></li>
<li><a href="/wiki/R._M._Hare" title="R. M. Hare">R. M. Hare</a></li>
<li><a href="/wiki/Peter_Singer" title="Peter Singer">Peter Singer</a></li>
<li><a href="/wiki/Derek_Parfit" title="Derek Parfit">Derek Parfit</a></li>
<li><a href="/wiki/Thomas_Nagel" title="Thomas Nagel">Thomas Nagel</a></li>
<li><a href="/wiki/Robert_Merrihew_Adams" title="Robert Merrihew Adams">Robert Merrihew Adams</a></li>
<li><a href="/wiki/Charles_Taylor_(philosopher)" title="Charles Taylor (philosopher)">Charles Taylor</a></li>
<li><a href="/wiki/Joxe_Azurmendi" title="Joxe Azurmendi">Joxe Azurmendi</a></li>
<li><a href="/wiki/Christine_Korsgaard" title="Christine Korsgaard">Christine Korsgaard</a></li>
<li><a href="/wiki/Martha_Nussbaum" title="Martha Nussbaum">Martha Nussbaum</a></li>
<li><b><a href="/wiki/List_of_ethicists" title="List of ethicists">more...</a></b></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Applied_ethics" title="Applied ethics">Applied ethics</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Bioethics" title="Bioethics">Bioethics</a></li>
<li><a href="/wiki/Business_ethics" title="Business ethics">Business ethics</a></li>
<li><a href="/wiki/Discourse_ethics" title="Discourse ethics">Discourse ethics</a></li>
<li><a href="/wiki/Engineering_ethics" title="Engineering ethics">Engineering ethics</a></li>
<li><a href="/wiki/Environmental_ethics" title="Environmental ethics">Environmental ethics</a></li>
<li><a href="/wiki/Legal_ethics" title="Legal ethics">Legal ethics</a></li>
<li><a href="/wiki/Media_ethics" title="Media ethics">Media ethics</a></li>
<li><a href="/wiki/Medical_ethics" title="Medical ethics">Medical ethics</a></li>
<li><a href="/wiki/Nursing_ethics" title="Nursing ethics">Nursing ethics</a></li>
<li><a href="/wiki/Professional_ethics" title="Professional ethics">Professional ethics</a></li>
<li><a href="/wiki/Sexual_ethics" title="Sexual ethics">Sexual ethics</a></li>
<li><a href="/wiki/Ethics_of_eating_meat" title="Ethics of eating meat">Ethics of eating meat</a></li>
<li><a href="/wiki/Ethics_of_technology" title="Ethics of technology">Ethics of technology</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Meta-ethics" title="Meta-ethics">Meta-ethics</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Cognitivism_(ethics)" title="Cognitivism (ethics)">Cognitivism</a>
<ul><li><a href="/wiki/Moral_realism" title="Moral realism">Moral realism</a>
<ul><li><a href="/wiki/Ethical_naturalism" title="Ethical naturalism">Ethical naturalism</a></li>
<li><a href="/wiki/Ethical_non-naturalism" title="Ethical non-naturalism">Ethical non-naturalism</a></li></ul></li>
<li><a href="/wiki/Ethical_subjectivism" title="Ethical subjectivism">Ethical subjectivism</a>
<ul><li><a href="/wiki/Ideal_observer_theory" title="Ideal observer theory">Ideal observer theory</a></li>
<li><a href="/wiki/Divine_command_theory" title="Divine command theory">Divine command theory</a></li></ul></li>
<li><a href="/wiki/Error_theory" class="mw-redirect" title="Error theory">Error theory</a></li></ul></li>
<li><a href="/wiki/Non-cognitivism" title="Non-cognitivism">Non-cognitivism</a>
<ul><li><a href="/wiki/Emotivism" title="Emotivism">Emotivism</a></li>
<li><a href="/wiki/Quasi-realism" title="Quasi-realism">Quasi-realism</a></li>
<li><a href="/wiki/Universal_prescriptivism" title="Universal prescriptivism">Universal prescriptivism</a></li></ul></li>
<li><a href="/wiki/Moral_universalism" title="Moral universalism">Moral universalism</a>
<ul><li><a href="/wiki/Value_monism" class="mw-redirect" title="Value monism">Value monism</a></li>
<li><a href="/wiki/Value_pluralism" title="Value pluralism">Value pluralism</a></li></ul></li>
<li><a href="/wiki/Moral_relativism" title="Moral relativism">Moral relativism</a></li>
<li><a href="/wiki/Moral_nihilism" title="Moral nihilism">Moral nihilism</a></li>
<li><a href="/wiki/Empiricism" title="Empiricism">Empiricism</a></li>
<li><a href="/wiki/Moral_rationalism" title="Moral rationalism">Moral rationalism</a></li>
<li><a href="/wiki/Ethical_intuitionism" title="Ethical intuitionism">Ethical intuitionism</a></li>
<li><a href="/wiki/Moral_skepticism" title="Moral skepticism">Moral skepticism</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Related articles</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em">
<ul><li><a href="/wiki/Christian_ethics" title="Christian ethics">Christian ethics</a></li>
<li><a href="/wiki/Descriptive_ethics" title="Descriptive ethics">Descriptive ethics</a></li>
<li><a href="/wiki/Ethics_in_religion" title="Ethics in religion">Ethics in religion</a></li>
<li><a href="/wiki/Evolutionary_ethics" title="Evolutionary ethics">Evolutionary ethics</a></li>
<li><a href="/wiki/Feminist_ethics" title="Feminist ethics">Feminist ethics</a></li>
<li><a href="/wiki/History_of_ethics" title="History of ethics">History of ethics</a></li>
<li><a href="/wiki/Ideology" title="Ideology">Ideology</a></li>
<li><a href="/wiki/Islamic_ethics" title="Islamic ethics">Islamic ethics</a></li>
<li><a href="/wiki/Jewish_ethics" title="Jewish ethics">Jewish ethics</a></li>
<li><a href="/wiki/Moral_psychology" title="Moral psychology">Moral psychology</a></li>
<li><a href="/wiki/Normative_ethics" title="Normative ethics">Normative ethics</a></li>
<li><a href="/wiki/Philosophy_of_law" title="Philosophy of law">Philosophy of law</a></li>
<li><a href="/wiki/Political_philosophy" title="Political philosophy">Political philosophy</a></li>
<li><a href="/wiki/Population_ethics" title="Population ethics">Population ethics</a></li>
<li><a href="/wiki/Social_philosophy" title="Social philosophy">Social philosophy</a></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><a href="/wiki/Category:Ethics" title="Category:Ethics">Category</a></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw1244
Cached time: 20191015202847
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 1.248 seconds
Real time usage: 1.560 seconds
Preprocessor visited node count: 3779/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 171746/2097152 bytes
Template argument size: 2419/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 9/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 188095/5000000 bytes
Number of Wikibase entities loaded: 4/400
Lua time usage: 0.607/10.000 seconds
Lua memory usage: 6.85 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1196.594      1 -total
 65.74%  786.599      1 Template:Reflist
 22.98%  274.950      8 Template:Cite_journal
 15.43%  184.595      5 Template:Citation_needed
 14.04%  167.989      5 Template:Fix
 13.91%  166.408     33 Template:Cite_web
 10.27%  122.907      6 Template:Cite_book
  7.91%   94.639     10 Template:Category_handler
  6.52%   77.986      9 Template:Cite_news
  5.26%   62.911      5 Template:Delink
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:13659583-0!canonical and timestamp 20191015202845 and revision id 917618573
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;oldid=917618573">https://en.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;oldid=917618573</a>"</div>
		
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Philosophy_of_artificial_intelligence" title="Category:Philosophy of artificial intelligence">Philosophy of artificial intelligence</a></li><li><a href="/wiki/Category:Ethics_of_science_and_technology" title="Category:Ethics of science and technology">Ethics of science and technology</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:CS1_maint:_others" title="Category:CS1 maint: others">CS1 maint: others</a></li><li><a href="/wiki/Category:CS1_errors:_dates" title="Category:CS1 errors: dates">CS1 errors: dates</a></li><li><a href="/wiki/Category:
Webarchive_template_wayback_links" title="Category:Webarchive template wayback links">Webarchive template wayback links</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_May_2015" title="Category:Articles with unsourced statements from May 2015">Articles with unsourced statements from May 2015</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_November_2017" title="Category:Articles with unsourced statements from November 2017">Articles with unsourced statements from November 2017</a></li><li><a href="/wiki/Category:Articles_to_be_expanded_from_May_2018" title="Category:Articles to be expanded from May 2018">Articles to be expanded from May 2018</a></li><li><a href="/wiki/Category:All_articles_to_be_expanded" title="Category:All articles to be expanded">All articles to be expanded</a></li><l
i><a href="/wiki/Category:Articles_using_small_message_boxes" title="Category:Articles using small message boxes">Articles using small message boxes</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>


		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Ethics+of+artificial+intelligence" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Ethics+of+artificial+intelligence" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="/wiki/Ethics_of_artificial_intelligence" title="View the content page [c]" accesskey="c">Article</a></span></li><li id="ca-talk"><span><a href="/wiki/Talk:Ethics_of_artificial_intelligence" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
						<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>
						<ul class="menu">
													</ul>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
							<li id="ca-view" class="collapsible selected"><span><a href="/wiki/Ethics_of_artificial_intelligence">Read</a></span></li><li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li><li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
						<h3 id="p-cactions-label"><span>More</span></h3>
						<ul class="menu">
													</ul>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>
						<form action="/w/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>	
			</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">
			<h3 id="p-interaction-label">Interaction</h3>
			<div class="body">
								<ul>
					<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Tools</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Ethics_of_artificial_intelligence" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Ethics_of_artificial_intelligence" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;oldid=917618573" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=info" title="More inform
ation about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q12727779" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Ethics_of_artificial_intelligence&amp;id=917618573" title="Information on how to cite this page">Cite this page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Print/export</h3>
			<div class="body">
								<ul>
					<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Ethics+of+artificial+intelligence">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Ethics+of+artificial+intelligence&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Ethics_of_artificial_intelligence&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">
			<h3 id="p-lang-label">Languages</h3>
			<div class="body">
								<ul>
					<li class="interlanguage-link interwiki-el"><a href="https://el.wikipedia.org/wiki/%CE%97%CE%B8%CE%B9%CE%BA%CE%AE_%CF%84%CE%B7%CF%82_%CF%84%CE%B5%CF%87%CE%BD%CE%B7%CF%84%CE%AE%CF%82_%CE%BD%CE%BF%CE%B7%CE%BC%CE%BF%CF%83%CF%8D%CE%BD%CE%B7%CF%82" title="Ηθική της τεχνητής νοημοσύνης – Greek" lang="el" hreflang="el" class="interlanguage-link-target">Ελληνικά</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/%C3%89tica_en_la_inteligencia_artificial" title="Ética en la inteligencia artificial – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%A7%D8%AE%D9%84%D8%A7%D9%82_%D9%87%D9%88%D8%B4_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C" title="اخلاق هوش مصنوعی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-li
nk interwiki-fr"><a href="https://fr.wikipedia.org/wiki/%C3%89thique_de_l%27intelligence_artificielle" title="Éthique de l&#039;intelligence artificielle – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%90%D7%AA%D7%99%D7%A7%D7%94_%D7%A9%D7%9C_%D7%91%D7%99%D7%A0%D7%94_%D7%9E%D7%9C%D7%90%D7%9B%D7%95%D7%AA%D7%99%D7%AA" title="אתיקה של בינה מלאכותית – Hebrew" lang="he" hreflang="he" class="interlanguage-link-target">עברית</a></li><li class="interlanguage-link interwiki-pt"><a href="https://pt.wikipedia.org/wiki/%C3%89tica_na_intelig%C3%AAncia_artificial" title="Ética na inteligência artificial – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ro"><a href="https://ro.wikipedia.org/wiki/Etica_privind_inteligen%C8%9Ba_artificial%C4%83" title="Etica privind inteligența artificială 
– Romanian" lang="ro" hreflang="ro" class="interlanguage-link-target">Română</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%AD%D1%82%D0%B8%D0%BA%D0%B0_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%B0" title="Этика искусственного интеллекта – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-sr"><a href="https://sr.wikipedia.org/wiki/Etika_ve%C5%A1ta%C4%8Dke_inteligencije" title="Etika veštačke inteligencije – Serbian" lang="sr" hreflang="sr" class="interlanguage-link-target">Српски / srpski</a></li><li class="interlanguage-link interwiki-sv"><a href="https://sv.wikipedia.org/wiki/Etiken_kring_artificiell_intelligens" title="Etiken kring artificiell intelligens – Swedish" lang="sv" hreflang="sv" class="interlanguage-link-target">Svenska</a></l
i>				</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q12727779#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-info">
								<li id="footer-info-lastmod"> This page was last edited on 24 September 2019, at 17:24<span class="anonymous-show">&#160;(UTC)</span>.</li>
								<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
							</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
								<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
								<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
								<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
								<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
								<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
							</ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-copyrightico">
						<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>					</li>
										<li id="footer-poweredbyico">
						<a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		

<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"1.248","walltime":"1.560","ppvisitednodes":{"value":3779,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":171746,"limit":2097152},"templateargumentsize":{"value":2419,"limit":2097152},"expansiondepth":{"value":12,"limit":40},"expensivefunctioncount":{"value":9,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":188095,"limit":5000000},"entityaccesscount":{"value":4,"limit":400},"timingprofile":["100.00% 1196.594      1 -total"," 65.74%  786.599      1 Template:Reflist"," 22.98%  274.950      8 Template:Cite_journal"," 15.43%  184.595      5 Template:Citation_needed"," 14.04%  167.989      5 Template:Fix"," 13.91%  166.408     33 Template:Cite_web"," 10.27%  122.907      6 Template:Cite_book","  7.91%   94.639     10 Template:Category_handler","  6.52%   77.986      9 Template:Cite_news","  5.26%   62.911      5 Template:Delink"]},"sc
ribunto":{"limitreport-timeusage":{"value":"0.607","limit":"10.000"},"limitreport-memusage":{"value":7184949,"limit":52428800},"limitreport-logs":"table#1 {\n}\ntable#1 {\n}\n"},"cachereport":{"origin":"mw1244","timestamp":"20191015202847","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Ethics of artificial intelligence","url":"https:\/\/en.wikipedia.org\/wiki\/Ethics_of_artificial_intelligence","sameAs":"http:\/\/www.wikidata.org\/entity\/Q12727779","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q12727779","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2007-10-10T08:24:29Z","dateModified":"2019-09-24T17:24:32Z","headline":"ethics of technology specific to robots and other artificially intelligent beings"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":125,"wgHostname":"mw1238"});});</script>
</body>
</html>
